{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 0.3867.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as DF\n",
    "\n",
    "train_data = pd.read_excel('训练_20180117.xlsx')\n",
    "train_data = train_data[train_data['Value']>=2]\n",
    "# test_data=pd.read_excel('测试A.xlsx')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.fillna(train_data.median(),inplace=True)\n",
    "test_data.fillna(test_data.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.to_csv('Train Median.csv',index=False)\n",
    "test_data.to_csv('Test B Mean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_data = pd.merge(test_data,test_ans,on=['ID'])\n",
    "# train_data = pd.concat([train_data,test_data],axis=0)\n",
    "test_data = pd.read_excel('测试B_20180117.xlsx')\n",
    "test_ID = test_data['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data['ID']\n",
    "del test_data['ID']\n",
    "\n",
    "All_NaN = DF(train_data.isnull().sum()).reset_index()\n",
    "All_NaN.columns = ['name','times']\n",
    "train_label = train_data['Value']\n",
    "del train_data['Value']\n",
    "\n",
    "feature_name_All_NaN = list(All_NaN[All_NaN['times']>int(len(train_data)*0.6)]['name'])\n",
    "feature_name = [i for i in train_data.columns if i not in feature_name_All_NaN]\n",
    "train_data = train_data[feature_name]\n",
    "test_data = test_data[feature_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TOOL', 'ERROR:#N/A', 'ERROR:#N/A_1', 'ERROR:#N/A_2', 'ERROR:#N/A_3', 'ERROR:#N/A_4', 'Tool', 'TOOL_ID', 'Tool (#1)', 'TOOL (#1)', 'Chamber ID', 'TOOL (#2)', 'ERROR:#N/A (#1)', 'ERROR:#N/A_1 (#1)', 'Tool (#2)', 'ERROR:#N/A (#2)', 'Tool (#3)', 'ERROR:#N/A (#3)', 'ERROR:#N/A_1 (#2)', 'ERROR:#N/A_2 (#1)', 'ERROR:#N/A_3 (#1)', 'ERROR:#N/A_4 (#1)', 'ERROR:#N/A_5', 'ERROR:#N/A_6', 'ERROR:#N/A_7', 'ERROR:#N/A_8', 'ERROR:#N/A_9', 'ERROR:#N/A_10', 'ERROR:#N/A_11', 'ERROR:#N/A_12', 'ERROR:#N/A_13', 'ERROR:#N/A_14', 'ERROR:#N/A_15', 'ERROR:#N/A_16', 'ERROR:#N/A_17', 'ERROR:#N/A_18', 'ERROR:#N/A_19', 'ERROR:#N/A_20', 'ERROR:#N/A_21', 'ERROR:#N/A_22', 'ERROR:#N/A_23', 'ERROR:#N/A_24', 'ERROR:#N/A_25', 'ERROR:#N/A_26', 'Tool (#4)', 'OPERATION_ID', 'Tool (#5)', 'Chamber', 'TOOL (#3)']\n",
      "1 TOOL Start: 210X1  End: 210X19  Len: 19  Time_total: 0\n",
      "2 ERROR:#N/A Start: ERROR:#N/A_1  End: ERROR:#N/A  Len: 0  Time_total: 0\n",
      "3 ERROR:#N/A_1 Start: ERROR:#N/A_2  End: ERROR:#N/A_1  Len: 0  Time_total: 0\n",
      "4 ERROR:#N/A_2 Start: 210X20  End: 210X215  Len: 194  Time_total: 4\n",
      "5 ERROR:#N/A_3 Start: ERROR:#N/A_4  End: ERROR:#N/A_3  Len: 0  Time_total: 0\n",
      "6 ERROR:#N/A_4 Start: 210X216  End: 210X231  Len: 16  Time_total: 0\n",
      "7 Tool Start: 220X1  End: 220X224  Len: 170  Time_total: 8\n",
      "8 TOOL_ID Start: 300X1  End: 300X21  Len: 21  Time_total: 10\n",
      "9 Tool (#1) Start: 310X1  End: 311X225  Len: 354  Time_total: 22\n",
      "10 TOOL (#1) Start: Chamber ID  End: TOOL (#1)  Len: 0  Time_total: 0\n",
      "11 Chamber ID Start: 312X1  End: 312X798  Len: 679  Time_total: 0\n",
      "12 TOOL (#2) Start: 330X1  End: 330X668  Len: 449  Time_total: 2\n",
      "13 ERROR:#N/A (#1) Start: 330X669  End: 330X688  Len: 14  Time_total: 0\n",
      "14 ERROR:#N/A_1 (#1) Start: 330X689  End: 330X1311  Len: 426  Time_total: 3\n",
      "15 Tool (#2) Start: 340X1  End: 340X30  Len: 27  Time_total: 0\n",
      "16 ERROR:#N/A (#2) Start: 340X31  End: 340X199  Len: 112  Time_total: 0\n",
      "17 Tool (#3) Start: 344X1  End: 344X173  Len: 118  Time_total: 0\n",
      "18 ERROR:#N/A (#3) Start: 344X174  End: 344X176  Len: 2  Time_total: 0\n",
      "19 ERROR:#N/A_1 (#2) Start: 344X177  End: 344X178  Len: 2  Time_total: 0\n",
      "20 ERROR:#N/A_2 (#1) Start: ERROR:#N/A_3 (#1)  End: ERROR:#N/A_2 (#1)  Len: 0  Time_total: 0\n",
      "21 ERROR:#N/A_3 (#1) Start: 344X181  End: 344X182  Len: 2  Time_total: 0\n",
      "22 ERROR:#N/A_4 (#1) Start: 344X183  End: 344X185  Len: 2  Time_total: 0\n",
      "23 ERROR:#N/A_5 Start: 344X186  End: 344X187  Len: 2  Time_total: 0\n",
      "24 ERROR:#N/A_6 Start: ERROR:#N/A_7  End: ERROR:#N/A_6  Len: 0  Time_total: 0\n",
      "25 ERROR:#N/A_7 Start: 344X190  End: 344X191  Len: 2  Time_total: 0\n",
      "26 ERROR:#N/A_8 Start: 344X192  End: 344X205  Len: 10  Time_total: 0\n",
      "27 ERROR:#N/A_9 Start: ERROR:#N/A_10  End: ERROR:#N/A_9  Len: 0  Time_total: 0\n",
      "28 ERROR:#N/A_10 Start: 344X208  End: 344X209  Len: 2  Time_total: 0\n",
      "29 ERROR:#N/A_11 Start: 344X210  End: 344X216  Len: 5  Time_total: 0\n",
      "30 ERROR:#N/A_12 Start: 344X218  End: 344X220  Len: 2  Time_total: 0\n",
      "31 ERROR:#N/A_13 Start: 344X221  End: 344X222  Len: 2  Time_total: 0\n",
      "32 ERROR:#N/A_14 Start: ERROR:#N/A_15  End: ERROR:#N/A_14  Len: 0  Time_total: 0\n",
      "33 ERROR:#N/A_15 Start: 344X225  End: 344X226  Len: 2  Time_total: 0\n",
      "34 ERROR:#N/A_16 Start: 344X227  End: 344X229  Len: 2  Time_total: 0\n",
      "35 ERROR:#N/A_17 Start: ERROR:#N/A_18  End: ERROR:#N/A_17  Len: 0  Time_total: 0\n",
      "36 ERROR:#N/A_18 Start: 344X230  End: 344X232  Len: 3  Time_total: 0\n",
      "37 ERROR:#N/A_19 Start: 344X233  End: 344X237  Len: 5  Time_total: 0\n",
      "38 ERROR:#N/A_20 Start: 344X239  End: 344X241  Len: 2  Time_total: 0\n",
      "39 ERROR:#N/A_21 Start: 344X243  End: 344X246  Len: 4  Time_total: 0\n",
      "40 ERROR:#N/A_22 Start: 344X248  End: 344X250  Len: 2  Time_total: 0\n",
      "41 ERROR:#N/A_23 Start: 344X252  End: 344X255  Len: 4  Time_total: 0\n",
      "42 ERROR:#N/A_24 Start: 344X257  End: 344X259  Len: 2  Time_total: 0\n",
      "43 ERROR:#N/A_25 Start: 344X261  End: 344X264  Len: 4  Time_total: 0\n",
      "44 ERROR:#N/A_26 Start: 344X266  End: 344X266  Len: 1  Time_total: 0\n",
      "45 Tool (#4) Start: 360X1  End: 420X230  Len: 1386  Time_total: 25\n",
      "46 OPERATION_ID Start: 440AX1  End: 440AX213  Len: 213  Time_total: 0\n",
      "47 Tool (#5) Start: 520X1  End: 520X377  Len: 336  Time_total: 10\n",
      "48 Chamber Start: 520X380  End: 520X434  Len: 46  Time_total: 0\n",
      "49 TOOL (#3) Start: 750X1  End: 750X1452  Len: 1030  Time_total: 6\n",
      "      times\n",
      "TOOL       \n",
      "J       142\n",
      "L       178\n",
      "M       128\n",
      "N       266\n",
      "O        85\n",
      "            times\n",
      "ERROR:#N/A       \n",
      "0             799\n",
      "              times\n",
      "ERROR:#N/A_1       \n",
      "-0.19             3\n",
      "-0.18            28\n",
      "-0.17            41\n",
      "-0.16            18\n",
      "-0.15            47\n",
      "-0.14           122\n",
      "-0.13           121\n",
      "-0.12            18\n",
      "-0.11             7\n",
      "-0.10             2\n",
      "-0.08             1\n",
      "-0.07             2\n",
      "-0.06             1\n",
      "-0.04             2\n",
      "-0.03             9\n",
      "-0.02             7\n",
      "-0.01             1\n",
      " 0.00             4\n",
      " 0.03             1\n",
      " 0.04             6\n",
      " 0.05            13\n",
      " 0.06            53\n",
      " 0.07            94\n",
      " 0.08            35\n",
      " 0.09             5\n",
      " 0.10             1\n",
      " 0.11             2\n",
      " 0.13             8\n",
      " 0.14            86\n",
      " 0.15            54\n",
      " 0.16             6\n",
      " 0.17             1\n",
      "              times\n",
      "ERROR:#N/A_2       \n",
      "0.00            120\n",
      "88.53             1\n",
      "88.57             1\n",
      "88.58             2\n",
      "88.59             5\n",
      "88.60             1\n",
      "88.61             2\n",
      "88.64             1\n",
      "88.66             1\n",
      "88.67             1\n",
      "88.68             1\n",
      "88.69             3\n",
      "88.72             1\n",
      "88.73             3\n",
      "88.75             2\n",
      "88.77             2\n",
      "88.79             2\n",
      "88.81             2\n",
      "88.83             2\n",
      "88.84             5\n",
      "88.85             1\n",
      "88.86             1\n",
      "88.87             1\n",
      "88.90             2\n",
      "88.91             1\n",
      "88.93             2\n",
      "88.94             1\n",
      "88.95             1\n",
      "88.97             1\n",
      "89.03             2\n",
      "...             ...\n",
      "100.90            3\n",
      "100.95            3\n",
      "101.00           16\n",
      "101.05           11\n",
      "101.10           10\n",
      "101.13            1\n",
      "101.15           18\n",
      "101.20           10\n",
      "101.25           28\n",
      "101.30           15\n",
      "101.35           14\n",
      "101.40           13\n",
      "101.45           15\n",
      "101.47            1\n",
      "101.50           11\n",
      "101.55           21\n",
      "101.60           20\n",
      "101.65           10\n",
      "101.70           26\n",
      "101.75           17\n",
      "101.80           12\n",
      "101.85            8\n",
      "101.90            2\n",
      "101.95            4\n",
      "102.00            6\n",
      "102.05            1\n",
      "102.10            3\n",
      "102.15            3\n",
      "102.25            2\n",
      "102.45            1\n",
      "\n",
      "[194 rows x 1 columns]\n",
      "              times\n",
      "ERROR:#N/A_3       \n",
      "1               799\n",
      "              times\n",
      "ERROR:#N/A_4       \n",
      "0                 4\n",
      "1194461964        1\n",
      "1194716434        1\n",
      "1194967727        1\n",
      "1195222280        1\n",
      "1196617492        1\n",
      "1196872087        1\n",
      "1198416345        1\n",
      "1198670923        1\n",
      "1198925586        1\n",
      "1672614498        1\n",
      "1672865809        1\n",
      "1675023665        1\n",
      "1675243837        1\n",
      "1675497453        1\n",
      "1678071233        1\n",
      "1678514274        1\n",
      "1678734683        1\n",
      "1679350143        1\n",
      "1679672324        1\n",
      "1680283797        1\n",
      "1685207504        1\n",
      "1685428106        1\n",
      "1685682592        1\n",
      "1688667549        1\n",
      "1688890980        1\n",
      "1689111437        1\n",
      "1690886918        1\n",
      "1691138169        1\n",
      "1691393247        1\n",
      "...             ...\n",
      "13250353191       1\n",
      "13274021905       1\n",
      "13274487611       1\n",
      "13274924723       1\n",
      "13296525495       1\n",
      "13296770460       1\n",
      "13297015358       1\n",
      "13301470620       1\n",
      "13303573990       1\n",
      "13304066715       1\n",
      "13307730120       1\n",
      "13309150479       1\n",
      "13321662174       1\n",
      "13321906895       1\n",
      "13325314346       1\n",
      "13327608994       1\n",
      "13333296736       1\n",
      "13333565030       1\n",
      "13338155754       1\n",
      "13343603306       1\n",
      "13343868920       1\n",
      "13360164054       1\n",
      "13361227707       1\n",
      "13362289297       1\n",
      "13363792419       1\n",
      "13368893453       1\n",
      "13369137225       1\n",
      "13370183446       1\n",
      "13463161931       1\n",
      "13550347519       1\n",
      "\n",
      "[785 rows x 1 columns]\n",
      "      times\n",
      "Tool       \n",
      "A       217\n",
      "B       582\n",
      "         times\n",
      "TOOL_ID       \n",
      "E          487\n",
      "N          312\n",
      "           times\n",
      "Tool (#1)       \n",
      "B            314\n",
      "C             47\n",
      "D              6\n",
      "E            432\n",
      "           times\n",
      "TOOL (#1)       \n",
      "K            109\n",
      "T            320\n",
      "V            370\n",
      "            times\n",
      "Chamber ID       \n",
      "1             138\n",
      "2             285\n",
      "3             376\n",
      "           times\n",
      "TOOL (#2)       \n",
      "A             21\n",
      "B            416\n",
      "C            250\n",
      "D            102\n",
      "E             10\n",
      "                 times\n",
      "ERROR:#N/A (#1)       \n",
      "0                  799\n",
      "                   times\n",
      "ERROR:#N/A_1 (#1)       \n",
      "0                    799\n",
      "           times\n",
      "Tool (#2)       \n",
      "V            755\n",
      "W             44\n",
      "                 times\n",
      "ERROR:#N/A (#2)       \n",
      "1                  334\n",
      "2                  239\n",
      "3                  226\n",
      "           times\n",
      "Tool (#3)       \n",
      "Q            120\n",
      "R            679\n",
      "                 times\n",
      "ERROR:#N/A (#3)       \n",
      "52                   7\n",
      "53                   1\n",
      "54                   4\n",
      "55                  51\n",
      "56                  16\n",
      "57                 124\n",
      "58                  44\n",
      "59                  64\n",
      "60                  54\n",
      "61                 144\n",
      "62                  21\n",
      "63                 118\n",
      "64                  54\n",
      "65                  19\n",
      "67                  27\n",
      "68                  12\n",
      "69                  21\n",
      "81                  18\n",
      "                   times\n",
      "ERROR:#N/A_1 (#2)       \n",
      "71.0                  10\n",
      "72.0                 212\n",
      "73.0                  43\n",
      "74.0                  40\n",
      "76.0                  13\n",
      "77.0                 194\n",
      "78.0                  31\n",
      "79.0                 157\n",
      "81.0                   1\n",
      "82.0                   3\n",
      "83.0                  26\n",
      "84.0                   8\n",
      "                   times\n",
      "ERROR:#N/A_2 (#1)       \n",
      "0                    799\n",
      "                   times\n",
      "ERROR:#N/A_3 (#1)       \n",
      "0.0                  736\n",
      "8.0                    2\n",
      "                   times\n",
      "ERROR:#N/A_4 (#1)       \n",
      "0                    799\n",
      "              times\n",
      "ERROR:#N/A_5       \n",
      "0.0               1\n",
      "527.0             1\n",
      "531.0             1\n",
      "547.0             1\n",
      "548.0             1\n",
      "549.0             2\n",
      "553.0             1\n",
      "554.0             4\n",
      "555.0             3\n",
      "556.0             4\n",
      "557.0             5\n",
      "558.0             7\n",
      "559.0             4\n",
      "560.0             6\n",
      "561.0             5\n",
      "562.0             4\n",
      "563.0             1\n",
      "564.0             2\n",
      "565.0             5\n",
      "566.0             3\n",
      "567.0             2\n",
      "569.0             2\n",
      "578.0             1\n",
      "588.0             2\n",
      "589.0             2\n",
      "590.0             1\n",
      "592.0             2\n",
      "593.0             1\n",
      "595.0             3\n",
      "596.0             2\n",
      "...             ...\n",
      "654.0             8\n",
      "655.0             6\n",
      "656.0             9\n",
      "657.0             3\n",
      "659.0             6\n",
      "660.0             2\n",
      "661.0             6\n",
      "662.0             4\n",
      "663.0             8\n",
      "664.0            10\n",
      "665.0            10\n",
      "666.0            14\n",
      "667.0            16\n",
      "668.0            17\n",
      "669.0            12\n",
      "670.0             5\n",
      "671.0             8\n",
      "672.0             6\n",
      "673.0             2\n",
      "674.0             5\n",
      "675.0             5\n",
      "676.0             4\n",
      "677.0             9\n",
      "678.0             1\n",
      "679.0             3\n",
      "721.0             1\n",
      "753.0             1\n",
      "852.0             1\n",
      "884.0             1\n",
      "907.0             1\n",
      "\n",
      "[116 rows x 1 columns]\n",
      "              times\n",
      "ERROR:#N/A_6       \n",
      "231               1\n",
      "232               1\n",
      "233               2\n",
      "234               8\n",
      "235               5\n",
      "236               1\n",
      "237               1\n",
      "238               2\n",
      "240               3\n",
      "244               2\n",
      "245               4\n",
      "246               1\n",
      "247               8\n",
      "248               7\n",
      "249               7\n",
      "250               6\n",
      "251               2\n",
      "252               1\n",
      "253               1\n",
      "254               3\n",
      "255               3\n",
      "256              11\n",
      "257              15\n",
      "258              27\n",
      "259              41\n",
      "260             123\n",
      "261             126\n",
      "262              76\n",
      "263              20\n",
      "265               1\n",
      "...             ...\n",
      "278               5\n",
      "315               2\n",
      "316               4\n",
      "317              12\n",
      "318               6\n",
      "319              25\n",
      "320               2\n",
      "321               3\n",
      "322               3\n",
      "332               5\n",
      "333               1\n",
      "335               1\n",
      "337               1\n",
      "657               1\n",
      "674               1\n",
      "679               1\n",
      "709               1\n",
      "714               1\n",
      "716               1\n",
      "721               1\n",
      "725               1\n",
      "732               1\n",
      "734               1\n",
      "762               1\n",
      "764               2\n",
      "770               1\n",
      "772               1\n",
      "779               1\n",
      "791               1\n",
      "797               1\n",
      "\n",
      "[71 rows x 1 columns]\n",
      "              times\n",
      "ERROR:#N/A_7       \n",
      "0.0               5\n",
      "62.0              1\n",
      "71.0              1\n",
      "94.0              1\n",
      "244.0             1\n",
      "245.0             8\n",
      "246.0             6\n",
      "247.0             7\n",
      "248.0             1\n",
      "249.0             3\n",
      "250.0             2\n",
      "251.0             6\n",
      "252.0             5\n",
      "253.0             7\n",
      "254.0             8\n",
      "255.0             8\n",
      "256.0            14\n",
      "257.0            16\n",
      "258.0            19\n",
      "259.0            16\n",
      "260.0             6\n",
      "261.0            18\n",
      "262.0            23\n",
      "263.0            33\n",
      "264.0            31\n",
      "265.0            66\n",
      "266.0            41\n",
      "267.0            65\n",
      "268.0            84\n",
      "269.0             8\n",
      "270.0             5\n",
      "271.0            41\n",
      "272.0            89\n",
      "273.0            48\n",
      "274.0            10\n",
      "275.0             3\n",
      "276.0             3\n",
      "277.0             3\n",
      "278.0             7\n",
      "279.0             4\n",
      "280.0             4\n",
      "281.0             5\n",
      "282.0             1\n",
      "283.0             5\n",
      "              times\n",
      "ERROR:#N/A_8       \n",
      "10002             1\n",
      "10003            10\n",
      "10004             5\n",
      "10005            10\n",
      "10006             5\n",
      "10007             6\n",
      "10008             7\n",
      "10009             3\n",
      "10010             4\n",
      "10011             1\n",
      "10012             1\n",
      "10013             2\n",
      "10014             2\n",
      "10015             1\n",
      "10020             2\n",
      "10022             1\n",
      "13002            26\n",
      "13003            30\n",
      "13004             5\n",
      "13005             2\n",
      "13006             1\n",
      "13007             1\n",
      "16002            27\n",
      "16003            73\n",
      "16004            38\n",
      "16005            31\n",
      "16006            33\n",
      "16007            33\n",
      "16008            25\n",
      "16009            37\n",
      "16010            39\n",
      "16011            49\n",
      "16012            29\n",
      "16013            39\n",
      "16014            24\n",
      "16015            28\n",
      "16016            25\n",
      "16017            26\n",
      "16018            15\n",
      "16019            19\n",
      "16020             7\n",
      "16021            14\n",
      "16022            13\n",
      "16023            10\n",
      "16024             4\n",
      "16025            14\n",
      "16026            11\n",
      "16027             1\n",
      "16028             5\n",
      "16029             1\n",
      "16030             1\n",
      "16031             1\n",
      "16034             1\n",
      "              times\n",
      "ERROR:#N/A_9       \n",
      "10000            61\n",
      "13000            65\n",
      "16000           673\n",
      "               times\n",
      "ERROR:#N/A_10       \n",
      "10000.0           65\n",
      "15000.0          673\n",
      "               times\n",
      "ERROR:#N/A_11       \n",
      "12                 1\n",
      "13                 3\n",
      "14                 6\n",
      "15                 2\n",
      "16                 2\n",
      "17                23\n",
      "18                71\n",
      "19                35\n",
      "20                24\n",
      "21               111\n",
      "22                79\n",
      "23               116\n",
      "24               144\n",
      "25                39\n",
      "26                19\n",
      "27                24\n",
      "28                 5\n",
      "29                14\n",
      "30                14\n",
      "31                 6\n",
      "37                 1\n",
      "38                 3\n",
      "39                 4\n",
      "40                 4\n",
      "41                 4\n",
      "42                 1\n",
      "43                 1\n",
      "51                 8\n",
      "54                17\n",
      "55                18\n",
      "               times\n",
      "ERROR:#N/A_12       \n",
      "0                799\n",
      "               times\n",
      "ERROR:#N/A_13       \n",
      "0.0              738\n",
      "               times\n",
      "ERROR:#N/A_14       \n",
      "3663               1\n",
      "3664               2\n",
      "3667               1\n",
      "3670               2\n",
      "3671               1\n",
      "3672               3\n",
      "3674               2\n",
      "3675               4\n",
      "3676               4\n",
      "3677               4\n",
      "3678               4\n",
      "3679               1\n",
      "3680               5\n",
      "3681               1\n",
      "3694               2\n",
      "3704               1\n",
      "3705               1\n",
      "3707               1\n",
      "3708               1\n",
      "3710               1\n",
      "3711               1\n",
      "3712               2\n",
      "3713               1\n",
      "3714               4\n",
      "3715               3\n",
      "3716               4\n",
      "3719               3\n",
      "3723               1\n",
      "4410               1\n",
      "4414               1\n",
      "...              ...\n",
      "4723               4\n",
      "4725               4\n",
      "4726               1\n",
      "4727               3\n",
      "4728               2\n",
      "4729              11\n",
      "4730               5\n",
      "4731               8\n",
      "4732              13\n",
      "4733              11\n",
      "4734              14\n",
      "4735               9\n",
      "4737               8\n",
      "4738               5\n",
      "4739               6\n",
      "4740               1\n",
      "4741               7\n",
      "4742               3\n",
      "4743               8\n",
      "4744              12\n",
      "4745              14\n",
      "4746              11\n",
      "4747              17\n",
      "4748              20\n",
      "4749              29\n",
      "4750              13\n",
      "4751              12\n",
      "4752               5\n",
      "4753               1\n",
      "4754               2\n",
      "\n",
      "[222 rows x 1 columns]\n",
      "               times\n",
      "ERROR:#N/A_15       \n",
      "0.0                1\n",
      "3666.0             1\n",
      "3674.0             1\n",
      "3677.0             1\n",
      "3679.0             1\n",
      "3681.0             3\n",
      "3682.0             2\n",
      "3683.0             3\n",
      "3684.0             6\n",
      "3685.0             3\n",
      "3686.0             1\n",
      "3687.0             2\n",
      "3688.0             2\n",
      "3689.0             1\n",
      "3691.0             1\n",
      "3694.0             1\n",
      "3696.0             3\n",
      "3697.0             2\n",
      "3698.0             2\n",
      "3699.0             7\n",
      "3700.0             2\n",
      "3701.0             1\n",
      "3702.0             3\n",
      "3704.0             1\n",
      "3710.0             1\n",
      "3711.0             1\n",
      "3720.0             1\n",
      "3722.0             1\n",
      "3724.0             1\n",
      "3725.0             3\n",
      "...              ...\n",
      "4241.0             4\n",
      "4242.0             3\n",
      "4243.0             3\n",
      "4245.0             5\n",
      "4246.0             7\n",
      "4247.0             7\n",
      "4248.0             4\n",
      "4249.0             5\n",
      "4250.0             7\n",
      "4251.0             6\n",
      "4252.0            13\n",
      "4253.0            12\n",
      "4254.0            15\n",
      "4255.0            23\n",
      "4256.0            18\n",
      "4257.0            11\n",
      "4258.0            23\n",
      "4259.0            22\n",
      "4260.0            19\n",
      "4261.0            11\n",
      "4262.0            23\n",
      "4263.0            11\n",
      "4264.0            16\n",
      "4265.0            20\n",
      "4266.0            25\n",
      "4267.0            20\n",
      "4268.0            22\n",
      "4269.0            15\n",
      "4270.0             1\n",
      "4271.0             3\n",
      "\n",
      "[147 rows x 1 columns]\n",
      "               times\n",
      "ERROR:#N/A_16       \n",
      "2                738\n",
      "5                 61\n",
      "               times\n",
      "ERROR:#N/A_17       \n",
      "3002.0             1\n",
      "3006.3             1\n",
      "3006.7             1\n",
      "3007.0             1\n",
      "3007.1             2\n",
      "3007.2             2\n",
      "3007.3             1\n",
      "3007.4             3\n",
      "3007.5             4\n",
      "3007.6             4\n",
      "3007.7             6\n",
      "3007.8             6\n",
      "3007.9             7\n",
      "3008.0            17\n",
      "3008.1            11\n",
      "3008.2             8\n",
      "3008.3            19\n",
      "3008.4            14\n",
      "3008.5            10\n",
      "3008.6            19\n",
      "3008.7            26\n",
      "3008.8            15\n",
      "3008.9            17\n",
      "3009.0            20\n",
      "3009.1             6\n",
      "3009.2            16\n",
      "3009.3            13\n",
      "3009.4             9\n",
      "3009.5             4\n",
      "3009.6             7\n",
      "...              ...\n",
      "3013.1            10\n",
      "3013.2             9\n",
      "3013.3            10\n",
      "3013.4             9\n",
      "3013.5             5\n",
      "3013.6             3\n",
      "3013.7             4\n",
      "3013.8             4\n",
      "3013.9             6\n",
      "3014.0            11\n",
      "3014.1             3\n",
      "3014.2             5\n",
      "3014.3            12\n",
      "3014.4            15\n",
      "3014.5            11\n",
      "3014.6            13\n",
      "3014.7            16\n",
      "3014.8            21\n",
      "3014.9            15\n",
      "3015.0            14\n",
      "3015.1             9\n",
      "3015.2             4\n",
      "3015.3            10\n",
      "3015.4             3\n",
      "3015.5             7\n",
      "3015.6             6\n",
      "3015.7             3\n",
      "3015.8             2\n",
      "3015.9             5\n",
      "3016.0             3\n",
      "\n",
      "[87 rows x 1 columns]\n",
      "               times\n",
      "ERROR:#N/A_18       \n",
      "3032               2\n",
      "3035              56\n",
      "3037             303\n",
      "3040             134\n",
      "3042             141\n",
      "3045             138\n",
      "3047              20\n",
      "3050               5\n",
      "               times\n",
      "ERROR:#N/A_19       \n",
      "3000             799\n",
      "               times\n",
      "ERROR:#N/A_20       \n",
      "97.2               1\n",
      "97.4               1\n",
      "97.5               3\n",
      "97.6               2\n",
      "97.7               2\n",
      "97.8               2\n",
      "97.9               5\n",
      "98.0               1\n",
      "98.6               1\n",
      "98.8               1\n",
      "99.0               6\n",
      "99.1              19\n",
      "99.2              37\n",
      "99.3              30\n",
      "99.4              25\n",
      "99.5              22\n",
      "99.6              18\n",
      "99.7              19\n",
      "99.8              25\n",
      "99.9              34\n",
      "100.0              8\n",
      "100.1              7\n",
      "100.2             11\n",
      "100.3              5\n",
      "100.4              3\n",
      "100.5              3\n",
      "100.6             12\n",
      "100.7              7\n",
      "100.8              5\n",
      "100.9              4\n",
      "...              ...\n",
      "109.3              1\n",
      "109.4              2\n",
      "109.5              3\n",
      "109.6              2\n",
      "109.7              4\n",
      "109.8             37\n",
      "109.9             36\n",
      "110.0             13\n",
      "110.1             21\n",
      "110.2              6\n",
      "110.3              6\n",
      "110.4              3\n",
      "110.5              6\n",
      "110.6             11\n",
      "110.7              7\n",
      "110.8              3\n",
      "110.9             11\n",
      "111.0             10\n",
      "111.1              4\n",
      "111.2             12\n",
      "111.3              8\n",
      "111.4              9\n",
      "111.5              7\n",
      "111.6              5\n",
      "111.7              4\n",
      "111.8              5\n",
      "111.9              2\n",
      "112.0              1\n",
      "112.1              3\n",
      "112.2              1\n",
      "\n",
      "[134 rows x 1 columns]\n",
      "               times\n",
      "ERROR:#N/A_21       \n",
      "104.5              1\n",
      "104.7              1\n",
      "104.8              1\n",
      "104.9              4\n",
      "105.0              2\n",
      "105.1              1\n",
      "105.2              1\n",
      "105.3              4\n",
      "105.4              6\n",
      "105.5              6\n",
      "105.6              6\n",
      "105.7              5\n",
      "105.8             10\n",
      "105.9             10\n",
      "106.0             13\n",
      "106.1             10\n",
      "106.2             18\n",
      "106.3              7\n",
      "106.4             14\n",
      "106.5             11\n",
      "106.6             18\n",
      "106.7             25\n",
      "106.8             27\n",
      "106.9             24\n",
      "107.0             20\n",
      "107.1             35\n",
      "107.2             27\n",
      "107.3             18\n",
      "107.4             30\n",
      "107.5             25\n",
      "107.6             26\n",
      "107.7             26\n",
      "107.8             19\n",
      "107.9             13\n",
      "108.0             28\n",
      "108.1             33\n",
      "108.2             29\n",
      "108.3             26\n",
      "108.4             29\n",
      "108.5             22\n",
      "108.6             12\n",
      "108.7             18\n",
      "108.8             16\n",
      "108.9              7\n",
      "109.0              5\n",
      "109.1             10\n",
      "109.2             16\n",
      "109.3             12\n",
      "109.4              6\n",
      "109.5              2\n",
      "109.7              2\n",
      "109.8              1\n",
      "               times\n",
      "ERROR:#N/A_22       \n",
      "110              799\n",
      "               times\n",
      "ERROR:#N/A_23       \n",
      "11.0               1\n",
      "18.0               1\n",
      "19.0               1\n",
      "28.0               1\n",
      "52.0               1\n",
      "58.0               1\n",
      "59.0               1\n",
      "60.0               2\n",
      "61.0               4\n",
      "62.0               2\n",
      "63.0               2\n",
      "64.0              11\n",
      "65.0              19\n",
      "66.0              16\n",
      "67.0              11\n",
      "68.0              12\n",
      "69.0              24\n",
      "70.0              47\n",
      "71.0              54\n",
      "72.0              30\n",
      "73.0              38\n",
      "74.0              50\n",
      "75.0              39\n",
      "76.0              37\n",
      "77.0              68\n",
      "78.0              37\n",
      "79.0              20\n",
      "80.0              32\n",
      "81.0              21\n",
      "82.0              21\n",
      "83.0              22\n",
      "84.0              16\n",
      "85.0              24\n",
      "86.0               6\n",
      "87.0               2\n",
      "88.0               2\n",
      "90.0               1\n",
      "91.0               2\n",
      "92.0              10\n",
      "93.0              10\n",
      "94.0               7\n",
      "95.0               8\n",
      "96.0               7\n",
      "97.0               5\n",
      "98.0               4\n",
      "99.0               2\n",
      "100.0              1\n",
      "101.0              2\n",
      "102.0              2\n",
      "116.0              1\n",
      "               times\n",
      "ERROR:#N/A_24       \n",
      "109.5              1\n",
      "109.7              7\n",
      "109.8            310\n",
      "109.9            463\n",
      "110.0             18\n",
      "               times\n",
      "ERROR:#N/A_25       \n",
      "101.2              2\n",
      "101.3              2\n",
      "101.4              4\n",
      "101.5              9\n",
      "101.6             18\n",
      "101.7             16\n",
      "101.8              9\n",
      "101.9             14\n",
      "102.0             22\n",
      "102.1             16\n",
      "102.2             22\n",
      "102.3             20\n",
      "102.4             22\n",
      "102.5             29\n",
      "102.6             46\n",
      "102.7             43\n",
      "102.8             71\n",
      "102.9             73\n",
      "103.0             70\n",
      "103.1             62\n",
      "103.2             34\n",
      "103.3             37\n",
      "103.4             22\n",
      "103.5             27\n",
      "103.6             18\n",
      "103.7              8\n",
      "103.8             11\n",
      "103.9              4\n",
      "104.0              1\n",
      "104.1              3\n",
      "104.2              3\n",
      "               times\n",
      "ERROR:#N/A_26       \n",
      "110              799\n",
      "           times\n",
      "Tool (#4)       \n",
      "A             18\n",
      "B            266\n",
      "C            191\n",
      "D            266\n",
      "E             58\n",
      "              times\n",
      "OPERATION_ID       \n",
      "XY1             697\n",
      "XY2             102\n",
      "           times\n",
      "Tool (#5)       \n",
      "11           641\n",
      "12             1\n",
      "14           157\n",
      "         times\n",
      "Chamber       \n",
      "1.0        212\n",
      "2.0        138\n",
      "3.0        173\n",
      "4.0        157\n",
      "5.0        110\n",
      "           times\n",
      "TOOL (#3)       \n",
      "A            231\n",
      "B            457\n",
      "C             67\n",
      "D             41\n",
      "E              3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "tool_name = []\n",
    "for i in train_data.columns:\n",
    "    if re.search('tool',i,re.IGNORECASE):\n",
    "        tool_name.append(i)\n",
    "    elif ('C' in i) | ('E' in i) | ('T' in i):\n",
    "        tool_name.append(i)\n",
    "\n",
    "print(tool_name)\n",
    "look_tool = train_data[tool_name]\n",
    "\n",
    "time_col_name = []\n",
    "no_tool_name = [i for i in train_data.columns if i not in tool_name]\n",
    "for i in no_tool_name:\n",
    "    if (str(train_data[i].mean())[0:4]=='2017') | (str(train_data[i].mean())[0:4]=='2016'):\n",
    "        time_col_name.append(i)\n",
    "        \n",
    "get_Time_columns = train_data[time_col_name]\n",
    "\n",
    "pos_tool = []\n",
    "for i in range(len(train_data.columns)):\n",
    "    j = train_data.columns[i]\n",
    "    if j in tool_name:\n",
    "        pos_tool.append(i)\n",
    "\n",
    "pos_tool.append(len(train_data.columns))\n",
    "\n",
    "for i in range(len(pos_tool)-1):\n",
    "    j = pos_tool[i]\n",
    "    k = pos_tool[i+1]\n",
    "    time_total = 0\n",
    "    for check in range(j+1,k-1):\n",
    "        if train_data.columns[check] in time_col_name:\n",
    "            time_total+=1\n",
    "    print(i+1,train_data.columns[j],'Start:',train_data.columns[j+1],' End:',train_data.columns[k-1],' Len:',k-j-1,' Time_total:',time_total)\n",
    "\n",
    "total_tool_time = DF()\n",
    "for i in tool_name:\n",
    "    print(DF(look_tool.groupby([i]).size(),columns=['times']))\n",
    "\n",
    "except_time_name = [i for i in train_data.columns if i not in time_col_name]\n",
    "train_data = train_data[except_time_name]\n",
    "test_data = test_data[except_time_name]\n",
    "except_tool = [i for i in train_data.columns if i not in tool_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.fillna(train_data.mean(),inplace=True)\n",
    "# test_data.fillna(test_data.mean(),inplace=True)\n",
    "# train_data.fillna(0,inplace=True)\n",
    "# test_data.fillna(0,inplace=True)\n",
    "train_data = pd.read_csv('Train Mean.csv')\n",
    "test_data = pd.read_csv('Test Mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data.to_csv('Train Mean.csv',index=False)\n",
    "# test_data.to_csv('Test Mean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Same :  4942\n"
     ]
    }
   ],
   "source": [
    "check_same = train_data.copy()\n",
    "check_same = check_same.describe().T\n",
    "check_same = check_same[check_same['std']!=0].T\n",
    "print('No Same : ',len(check_same.columns))\n",
    "\n",
    "import scipy.stats as stats\n",
    "dict_corr = {\n",
    "    'spearman' : [],\n",
    "    'pearson' : [],\n",
    "    'kendall' : [],\n",
    "    'columns' : []\n",
    "}\n",
    "for i in train_data[except_tool].columns:\n",
    "    corr_pear,pval = stats.pearsonr(train_data[i],train_label)\n",
    "    corr_spear,pval = stats.spearmanr(train_data[i],train_label)\n",
    "    corr_kendall,pval = stats.kendalltau(train_data[i],train_label)\n",
    "    dict_corr['pearson'].append(abs(corr_pear))\n",
    "    dict_corr['spearman'].append(abs(corr_spear))\n",
    "    dict_corr['kendall'].append(abs(corr_kendall))\n",
    "    dict_corr['columns'].append(i)\n",
    "\n",
    "from pandas import DataFrame as DF\n",
    "corr_val = DF(dict_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson : 1704\n",
      "Spearman : 1831\n",
      "Kendall : 1710\n",
      "No Same Pearson : 1704\n",
      "No Same Spearman : 1831\n",
      "No Same Kendall:  1710\n",
      "Std Pearson : 714\n",
      "Std spearman : 806\n",
      "Std kendall : 731\n"
     ]
    }
   ],
   "source": [
    "pearson_feature = list(corr_val[corr_val['pearson']>=0.1]['columns'])\n",
    "spearman_feature =  list(corr_val[corr_val['spearman']>=0.1]['columns'])\n",
    "kendall_feature = list(corr_val[corr_val['kendall']>=0.075]['columns'])\n",
    "print('Pearson :',len(pearson_feature))\n",
    "print('Spearman :',len(spearman_feature))\n",
    "print('Kendall :',len(kendall_feature))\n",
    "\n",
    "feature_name_pearson = [i for i in check_same.columns if i in pearson_feature]\n",
    "feature_name_spearman = [i for i in check_same.columns if i in spearman_feature]\n",
    "feature_name_kendall = [i for i in check_same.columns if i in kendall_feature]\n",
    "print('No Same Pearson :',len(feature_name_pearson))\n",
    "print('No Same Spearman :',len(feature_name_spearman))\n",
    "print('No Same Kendall: ',len(feature_name_kendall))\n",
    "\n",
    "train_check_std_pearson = DF(train_data[feature_name_pearson].describe().T['std']).reset_index()\n",
    "test_check_std_pearson = DF(test_data[feature_name_pearson].describe().T['std']).reset_index()\n",
    "\n",
    "train_check_std_spearman = DF(train_data[feature_name_spearman].describe().T['std']).reset_index()\n",
    "test_check_std_spearman = DF(test_data[feature_name_spearman].describe().T['std']).reset_index()\n",
    "\n",
    "train_check_std_kendall = DF(train_data[feature_name_kendall].describe().T['std']).reset_index()\n",
    "test_check_std_kendall = DF(test_data[feature_name_kendall].describe().T['std']).reset_index()\n",
    "\n",
    "check_std_pearson = DF()\n",
    "check_std_pearson['name'] = train_check_std_pearson['index']\n",
    "check_std_pearson['std'] = train_check_std_pearson['std']/test_check_std_pearson['std']\n",
    "check_std_pearson = check_std_pearson[check_std_pearson['std']<=1.25]\n",
    "check_std_pearson = check_std_pearson[check_std_pearson['std']>=0.8]\n",
    "feature_name_std_pearson = list(check_std_pearson['name'])\n",
    "print('Std Pearson :',len(feature_name_std_pearson))\n",
    "\n",
    "check_std_spearman = DF()\n",
    "check_std_spearman['name'] = train_check_std_spearman['index']\n",
    "check_std_spearman['std'] = train_check_std_spearman['std']/test_check_std_spearman['std']\n",
    "check_std_spearman = check_std_spearman[check_std_spearman['std']<=1.25]\n",
    "check_std_spearman = check_std_spearman[check_std_spearman['std']>=0.8]\n",
    "feature_name_std_spearman = list(check_std_spearman['name'])\n",
    "print('Std spearman :',len(feature_name_std_spearman))\n",
    "\n",
    "check_std_kendall = DF()\n",
    "check_std_kendall['name'] = train_check_std_kendall['index']\n",
    "check_std_kendall['std'] = train_check_std_kendall['std']/test_check_std_kendall['std']\n",
    "check_std_kendall = check_std_kendall[check_std_kendall['std']<=1.25]\n",
    "check_std_kendall = check_std_kendall[check_std_kendall['std']>=0.8]\n",
    "feature_name_std_kendall = list(check_std_kendall['name'])\n",
    "print('Std kendall :',len(feature_name_std_kendall))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "le = LabelEncoder()\n",
    "train_tool_label = train_data[tool_name]\n",
    "test_tool_label = test_data[tool_name]\n",
    "for i in train_tool_label.columns:\n",
    "    le.fit(np.hstack([train_tool_label[i], test_tool_label[i]]))\n",
    "    min_max_scaler = MinMaxScaler() \n",
    "    train_tool_label[i] = min_max_scaler.fit_transform(le.transform(train_tool_label[i]).reshape(-1,1))\n",
    "    del min_max_scaler\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    test_tool_label[i] = min_max_scaler.fit_transform(le.transform(test_tool_label[i]).reshape(-1,1))\n",
    "    del min_max_scaler\n",
    "\n",
    "merge_dummies_tool = pd.concat([train_data[tool_name],test_data[tool_name]],axis=0).astype('str')\n",
    "merge_dummies_tool = pd.get_dummies(merge_dummies_tool)\n",
    "train_dummies_tool = merge_dummies_tool[:len(train_data)]\n",
    "test_dummies_tool = merge_dummies_tool[len(train_data):]\n",
    "\n",
    "def get_min_max(corr_str):\n",
    "\tif corr_str == 'pearson':\n",
    "\t\tfeature_name_std = [i for i in feature_name_std_pearson] \n",
    "\telif corr_str == 'spearman' :\n",
    "\t\tfeature_name_std = [i for i in feature_name_std_spearman] \n",
    "\telse:\n",
    "\t\tfeature_name_std = [i for i in feature_name_std_kendall]\n",
    "\tmin_max_scaler = MinMaxScaler()\n",
    "\tX_train_minmax = DF(min_max_scaler.fit_transform(train_data[feature_name_std]),columns=train_data[feature_name_std].columns)\n",
    "\tdel min_max_scaler\n",
    "\tmin_max_scaler = MinMaxScaler()\n",
    "\tX_test_minmax = DF(min_max_scaler.fit_transform(test_data[feature_name_std]),columns=test_data[feature_name_std].columns)\n",
    "\tdel min_max_scaler\n",
    "\n",
    "\treturn X_train_minmax, X_test_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop=True,inplace=True)\n",
    "train_dummies_tool.reset_index(drop=True,inplace=True)\n",
    "train_tool_label.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 5632)\n",
      "(799, 433)\n",
      "(300, 430)\n"
     ]
    }
   ],
   "source": [
    "print(train_data[feature_name_std].shape)\n",
    "print(train_data[feature_name_std_pearson].T.drop_duplicates().T.shape)\n",
    "print(test_data[feature_name_std_pearson].T.drop_duplicates().T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (799, 714)\n",
      "Dummies:  (799, 2641)\n",
      "Tool Label:  (799, 49)\n",
      "Need To Del : []\n",
      "X_train_pearson Shape  (799, 3404)\n",
      "Length Mean 792\n"
     ]
    }
   ],
   "source": [
    "X_train_minmax, X_test_minmax = get_min_max('pearson')\n",
    "print('Train :',X_train_minmax.shape)\n",
    "print('Dummies: ',train_dummies_tool.shape)\n",
    "print('Tool Label: ',train_tool_label.shape)\n",
    "X_train_pearson = pd.concat([X_train_minmax,train_tool_label,train_dummies_tool],axis=1)\n",
    "X_test_pearson = pd.concat([X_test_minmax,test_tool_label,test_dummies_tool],axis=1)\n",
    "\n",
    "del_not_test = [i for i in X_train_pearson.columns if i not in X_test_pearson.columns]\n",
    "print('Need To Del :',del_not_test)\n",
    "for i in del_not_test:\n",
    "    del X_train[i]\n",
    "    \n",
    "# X_train_pearson = X_train_pearson[feature_name_std_pearson]\n",
    "# X_test_pearson = X_test_pearson[feature_name_std_pearson]\n",
    "print('X_train_pearson Shape ',X_train_pearson.shape)\n",
    "\n",
    "X_mean_choose = X_train_pearson.describe().T['mean']/X_test_pearson.describe().T['mean']\n",
    "X_mean_choose = X_mean_choose[X_mean_choose>=0.5222]\n",
    "X_mean_choose = X_mean_choose[X_mean_choose<=1.5777]\n",
    "X_mean_name = list(DF(X_mean_choose).T.columns)\n",
    "print('Length Mean',len(X_mean_choose))\n",
    "\n",
    "X_train_pearson_mean = X_train_pearson[X_mean_name]\n",
    "X_test_pearson_mean = X_test_pearson[X_mean_name]\n",
    "mean_svr_model = SVR(kernel='rbf',C=1).fit(X_train_pearson[X_mean_name],train_label)\n",
    "result_mean_pearson = mean_svr_model.predict(X_test_pearson[X_mean_name])\n",
    "# result_mean_pearson 0.3867\n",
    "\n",
    "sub = DF()\n",
    "sub['ID'] = test_ID\n",
    "sub['Pre'] = result_mean_pearson\n",
    "sub.to_csv(\"ans/submission_std_mean0.5222_1.5777_pearson.csv\", index=False,header=False)\n",
    "fuck_name_no_pearson = [i for i in train_data.columns if i not in X_mean_name]\n",
    "# DF(X_mean_name).to_csv('1500 Mean Std Name.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (799, 806)\n",
      "Dummies:  (799, 2641)\n",
      "Tool Label:  (799, 49)\n",
      "Need To Del : []\n",
      "X_train_spearman Shape  (799, 3496)\n",
      "Length Mean:  883\n"
     ]
    }
   ],
   "source": [
    "X_train_minmax, X_test_minmax = get_min_max('spearman')\n",
    "print('Train :',X_train_minmax.shape)\n",
    "print('Dummies: ',train_dummies_tool.shape)\n",
    "print('Tool Label: ',train_tool_label.shape)\n",
    "X_train_spearman = pd.concat([X_train_minmax,train_tool_label,train_dummies_tool],axis=1)\n",
    "X_test_spearman = pd.concat([X_test_minmax,test_tool_label,test_dummies_tool],axis=1)\n",
    "\n",
    "del_not_test = [i for i in X_train_spearman.columns if i not in X_test_spearman.columns]\n",
    "print('Need To Del :',del_not_test)\n",
    "for i in del_not_test:\n",
    "    del X_train[i]\n",
    "\n",
    "# X_train_spearman = X_train_spearman[feature_name_std_spearman]\n",
    "# X_test_spearman = X_test_spearman[feature_name_std_spearman]\n",
    "print('X_train_spearman Shape ',X_train_spearman.shape)\n",
    "\n",
    "X_mean_choose = X_train_spearman.describe().T['mean']/X_test_spearman.describe().T['mean']\n",
    "X_mean_choose = X_mean_choose[X_mean_choose>=0.5222]\n",
    "X_mean_choose = X_mean_choose[X_mean_choose<=1.5777]\n",
    "X_mean_name = list(DF(X_mean_choose).T.columns)\n",
    "print('Length Mean: ',len(X_mean_choose))\n",
    "\n",
    "X_train_spearman_mean = X_train_spearman[X_mean_name]\n",
    "X_test_spearman_mean = X_test_spearman[X_mean_name]\n",
    "mean_svr_model = SVR(kernel='rbf',C=1).fit(X_train_spearman[X_mean_name],train_label)\n",
    "result_mean_spearman = mean_svr_model.predict(X_test_spearman[X_mean_name])\n",
    "# result_mean_spearman 0.3912\n",
    "\n",
    "sub = DF()\n",
    "sub['ID'] = test_ID\n",
    "sub['Pre'] = result_mean_spearman\n",
    "sub.to_csv(\"ans/submission_std_mean0.5222_1.5777_spearman.csv\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (799, 731)\n",
      "Dummies:  (799, 2641)\n",
      "Tool Label:  (799, 49)\n",
      "(799, 3421)\n",
      "Need To Del : []\n",
      "X_train_kendall Shape  (799, 3421)\n",
      "Length Mean:  805\n"
     ]
    }
   ],
   "source": [
    "X_train_minmax, X_test_minmax = get_min_max('kendall')\n",
    "print('Train :',X_train_minmax.shape)\n",
    "print('Dummies: ',train_dummies_tool.shape)\n",
    "print('Tool Label: ',train_tool_label.shape)\n",
    "X_train_kendall = pd.concat([X_train_minmax,train_tool_label,train_dummies_tool],axis=1)\n",
    "X_test_kendall = pd.concat([X_test_minmax,test_tool_label,test_dummies_tool],axis=1)\n",
    "print(X_train_kendall.shape)\n",
    "\n",
    "del_not_test = [i for i in X_train_kendall.columns if i not in X_test_kendall.columns]\n",
    "print('Need To Del :',del_not_test)\n",
    "for i in del_not_test:\n",
    "    del X_train[i]\n",
    "    \n",
    "# X_train_kendall = X_train_kendall[feature_name_std_kendall]\n",
    "# X_test_kendall = X_test_kendall[feature_name_std_kendall]\n",
    "print('X_train_kendall Shape ',X_train_kendall.shape)\n",
    "\n",
    "X_mean_choose = X_train_kendall.describe().T['mean']/X_test_kendall.describe().T['mean']\n",
    "X_mean_choose = X_mean_choose[X_mean_choose>=0.5222]\n",
    "X_mean_choose = X_mean_choose[X_mean_choose<=1.5777]\n",
    "X_mean_name = list(DF(X_mean_choose).T.columns)\n",
    "print('Length Mean: ',len(X_mean_choose))\n",
    "\n",
    "X_train_kendall_mean = X_train_kendall[X_mean_name]\n",
    "X_test_kendall_mean = X_test_kendall[X_mean_name]\n",
    "mean_svr_model = SVR(kernel='rbf',C=1).fit(X_train_kendall[X_mean_name],train_label)\n",
    "result_mean_kendall = mean_svr_model.predict(X_test_kendall[X_mean_name])\n",
    "# result_mean_kendall ？\n",
    "\n",
    "sub = DF()\n",
    "sub['ID'] = test_ID\n",
    "sub['Pre'] = result_mean_kendall\n",
    "sub.to_csv(\"ans/submission_std_mean0.5222-1.5777_kendall.csv\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calc Std ...\n",
      "In Pearson Feature, in Spearman:  3303  Pearson All:  3404\n",
      "In Pearson Feature, in Kendall:  3280  Pearson All:  3404\n",
      "In Spearman Feature ,in Kendall:  3413  Spearman All:  3496\n",
      "In Spearman Feature ,in Pearson:  3303  Spearman All:  3496\n",
      "In Kendall Feature ,in Pearson:  3280  Kendall All:  3421\n",
      "In Kendall Feature ,in Spearman:  3413  Kendall All:  3421\n",
      "交集:  3275\n",
      "Calc Std&Mean ...\n",
      "In Pearson Feature, in Spearman:  694  Pearson All:  792\n",
      "In Pearson Feature, in Kendall:  669  Pearson All:  792\n",
      "In Spearman Feature ,in Kendall:  800  Spearman All:  883\n",
      "In Spearman Feature ,in Pearson:  694  Spearman All:  883\n",
      "In Kendall Feature ,in Pearson:  669  Kendall All:  805\n",
      "In Kendall Feature ,in Spearman:  800  Kendall All:  805\n",
      "交集:  666\n"
     ]
    }
   ],
   "source": [
    "print('Calc Std ...')\n",
    "print(\"In Pearson Feature, in Spearman: \",len([i for i in X_train_pearson.columns if i in X_train_spearman.columns]),' Pearson All: ',len(X_train_pearson.columns))\n",
    "print(\"In Pearson Feature, in Kendall: \",len([i for i in X_train_pearson.columns if i in X_train_kendall.columns]),' Pearson All: ',len(X_train_pearson.columns))\n",
    "print(\"In Spearman Feature ,in Kendall: \",len([i for i in X_train_spearman.columns if i in X_train_kendall.columns]),' Spearman All: ',len(X_train_spearman.columns))\n",
    "print(\"In Spearman Feature ,in Pearson: \",len([i for i in X_train_spearman.columns if i in X_train_pearson.columns]),' Spearman All: ',len(X_train_spearman.columns))\n",
    "print(\"In Kendall Feature ,in Pearson: \",len([i for i in X_train_kendall.columns if i in X_train_pearson.columns]),' Kendall All: ',len(X_train_kendall.columns))\n",
    "print(\"In Kendall Feature ,in Spearman: \",len([i for i in X_train_kendall.columns if i in X_train_spearman.columns]),' Kendall All: ',len(X_train_kendall.columns))\n",
    "print(\"交集: \",len([i for i in X_train_kendall.columns if i in (X_train_pearson.columns) & (X_train_spearman.columns)]))\n",
    "\n",
    "print('Calc Std&Mean ...')\n",
    "print(\"In Pearson Feature, in Spearman: \",len([i for i in X_train_pearson_mean.columns if i in X_train_spearman_mean.columns]),' Pearson All: ',len(X_train_pearson_mean.columns))\n",
    "print(\"In Pearson Feature, in Kendall: \",len([i for i in X_train_pearson_mean.columns if i in X_train_kendall_mean.columns]),' Pearson All: ',len(X_train_pearson_mean.columns))\n",
    "print(\"In Spearman Feature ,in Kendall: \",len([i for i in X_train_spearman_mean.columns if i in X_train_kendall_mean.columns]),' Spearman All: ',len(X_train_spearman_mean.columns))\n",
    "print(\"In Spearman Feature ,in Pearson: \",len([i for i in X_train_spearman_mean.columns if i in X_train_pearson_mean.columns]),' Spearman All: ',len(X_train_spearman_mean.columns))\n",
    "print(\"In Kendall Feature ,in Pearson: \",len([i for i in X_train_kendall_mean.columns if i in X_train_pearson_mean.columns]),' Kendall All: ',len(X_train_kendall_mean.columns))\n",
    "print(\"In Kendall Feature ,in Spearman: \",len([i for i in X_train_kendall_mean.columns if i in X_train_spearman_mean.columns]),' Kendall All: ',len(X_train_kendall_mean.columns))\n",
    "print(\"交集: \",len([i for i in X_train_kendall_mean.columns if i in (X_train_pearson_mean.columns) & (X_train_spearman_mean.columns)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score as cv\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "feature_3_name_std = [i for i in X_train_kendall.columns if i in (X_train_pearson.columns) & (X_train_spearman.columns)]\n",
    "feature_3_name_mean = [i for i in X_train_kendall_mean.columns if i in(X_train_pearson_mean.columns) & (X_train_spearman_mean.columns)]\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=130,max_depth=7).fit(X_train_kendall[feature_3_name_std],train_label)\n",
    "xgb_model = xgb.XGBRegressor().fit(X_train_kendall[feature_3_name_std],train_label)\n",
    "svr_model = SVR(C=1.2).fit(X_train_kendall[feature_3_name_std],train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_ans1 = SVR(C=1.2).fit(X_train_kendall[feature_3_name_std],train_label).predict(X_test_kendall[feature_3_name_std])\n",
    "std_ans2 = lgb.LGBMRegressor(n_estimators=130,max_depth=7).fit(X_train_kendall[feature_3_name_std],train_label).predict(X_test_kendall[feature_3_name_std])\n",
    "std_ans3 = xgb.XGBRegressor().fit(X_train_kendall[feature_3_name_std],train_label).predict(X_test_kendall[feature_3_name_std])\n",
    "\n",
    "mean_ans1 = SVR(C=1.2).fit(X_train_kendall[feature_3_name_mean],train_label).predict(X_test_kendall[feature_3_name_mean])\n",
    "mean_ans2 = lgb.LGBMRegressor(n_estimators=130,max_depth=7).fit(X_train_kendall[feature_3_name_mean],train_label).predict(X_test_kendall[feature_3_name_mean])\n",
    "mean_ans3 = xgb.XGBRegressor().fit(X_train_kendall[feature_3_name_mean],train_label).predict(X_test_kendall[feature_3_name_mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean...\n",
      "0.0376989029404\n",
      "[ 0.02878657  0.05099155  0.03703162  0.04766475  0.03159153  0.03415445\n",
      "  0.05371654  0.02749044  0.02707521  0.03848637]\n",
      "0.0257221765847\n",
      "[ 0.02290959  0.02470608  0.02972927  0.02174356  0.02769421  0.02075158\n",
      "  0.03838125  0.01826704  0.01967751  0.03336168]\n",
      "0.0235160309731\n",
      "[ 0.01938368  0.0254739   0.02706504  0.02218931  0.02389066  0.02099386\n",
      "  0.03259971  0.0162667   0.01639524  0.03090222]\n",
      "0.0225150399173\n",
      "[ 0.01891128  0.02496477  0.02855236  0.02008069  0.01970023  0.01996295\n",
      "  0.02772619  0.01729464  0.01567991  0.03227738]\n"
     ]
    }
   ],
   "source": [
    "print('Mean...')\n",
    "no_tool_no_minmax_train_name = [i for i in feature_3_name_mean if i not in train_dummies_tool.columns]\n",
    "no_tool_no_minmax_train_name = [i for i in no_tool_no_minmax_train_name if i not in train_tool_label.columns]\n",
    "train_no_minmax = pd.concat([train_data[no_tool_no_minmax_train_name],train_tool_label,train_dummies_tool],axis=1)\n",
    "test_no_minmax = pd.concat([test_data[no_tool_no_minmax_train_name],test_tool_label,test_dummies_tool],axis=1)\n",
    "cv_result_no_minmax = -cv(Lasso(),train_no_minmax[feature_3_name_mean],train_label,cv=10,n_jobs=4,scoring='mean_squared_error')\n",
    "print(cv_result_no_minmax.mean())\n",
    "print(cv_result_no_minmax)\n",
    "cv_result = cv(SVR(C=1.2),X_train_kendall[feature_3_name_mean],train_label,cv=10,n_jobs=4,scoring='mean_squared_error')\n",
    "cv_result = -cv_result\n",
    "print(cv_result.mean())\n",
    "print(cv_result)\n",
    "\n",
    "cv_result = cv(lgb.LGBMRegressor(n_estimators=130,max_depth=5),X_train_kendall[feature_3_name_mean],train_label,cv=10,scoring='mean_squared_error')\n",
    "cv_result = -cv_result\n",
    "print(cv_result.mean())\n",
    "print(cv_result)\n",
    "\n",
    "cv_result = cv(xgb.XGBRegressor(max_depth=3),X_train_kendall[feature_3_name_mean],train_label,cv=10,scoring='mean_squared_error')\n",
    "cv_result = -cv_result\n",
    "print(cv_result.mean())\n",
    "print(cv_result)\n",
    "\n",
    "# mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std ..\n",
      "0.0309312279612\n",
      "[ 0.02238388  0.04013134  0.03723592  0.03634489  0.02195373  0.03156989\n",
      "  0.03973431  0.0195813   0.02082552  0.03955151]\n",
      "0.025813484092\n",
      "[ 0.02715381  0.02341276  0.02919989  0.02416344  0.02606629  0.0240375\n",
      "  0.03730418  0.01489523  0.01787166  0.03403008]\n",
      "0.0235886187998\n",
      "[ 0.02250703  0.02595222  0.02636674  0.02068538  0.02328762  0.02058858\n",
      "  0.03154968  0.01734394  0.01694522  0.03065977]\n",
      "0.0219618372349\n",
      "[ 0.01988708  0.02380942  0.02799426  0.0213116   0.02234014  0.02015743\n",
      "  0.02339597  0.01714743  0.01494268  0.02863236]\n"
     ]
    }
   ],
   "source": [
    "print('Std ..')\n",
    "no_tool_no_minmax_train_name = [i for i in feature_3_name_std if i not in train_dummies_tool.columns]\n",
    "no_tool_no_minmax_train_name = [i for i in no_tool_no_minmax_train_name if i not in train_tool_label.columns]\n",
    "train_no_minmax = pd.concat([train_data[no_tool_no_minmax_train_name],train_tool_label,train_dummies_tool],axis=1)\n",
    "test_no_minmax = pd.concat([test_data[no_tool_no_minmax_train_name],test_tool_label,test_dummies_tool],axis=1)\n",
    "cv_result_no_minmax = -cv(Lasso(),train_no_minmax[feature_3_name_std],train_label,cv=10,n_jobs=4,scoring='mean_squared_error')\n",
    "print(cv_result_no_minmax.mean())\n",
    "print(cv_result_no_minmax)\n",
    "cv_result = cv(SVR(C=1.2),X_train_kendall[feature_3_name_std],train_label,cv=10,n_jobs=4,scoring='mean_squared_error')\n",
    "cv_result = -cv_result\n",
    "print(cv_result.mean())\n",
    "print(cv_result)\n",
    "\n",
    "cv_result = cv(lgb.LGBMRegressor(n_estimators=130,max_depth=5),X_train_kendall[feature_3_name_std],train_label,cv=10,scoring='mean_squared_error')\n",
    "cv_result = -cv_result\n",
    "print(cv_result.mean())\n",
    "print(cv_result)\n",
    "\n",
    "cv_result = cv(xgb.XGBRegressor(),X_train_kendall[feature_3_name_std],train_label,cv=10,scoring='mean_squared_error')\n",
    "cv_result = -cv_result\n",
    "print(cv_result.mean())\n",
    "print(cv_result)\n",
    "\n",
    "# SVR (3 name = 738, 1.25 0.8)\n",
    "# Spearman online 0.03981 - offline 0.03153\n",
    "# Kendall online 0.04011 - offline 0.03158 \n",
    "# Pearson online 0.03867 - offline 0.03084\n",
    "# Feature 3 name online 0.03862 - offline 0.03059 (738 pearson 1 spearman 1 kendall 0.8) \n",
    "# 0.03048 (696 pearson 1 spearman 1 keandall 0.75)\n",
    "# 0.0303967 (723 pearson 1 spearman 1 kendall 0.75 std 1.3 0.8)\n",
    "# 0.0303975 (769 pearson 1 spearman 1 kendall 0.75 std 1.4 0.8)\n",
    "# 0.0303370 (745 pearson 1 spearman 1 kendall 0.75 std 1.35 0.8)\n",
    "# 0.0303244 (743 pearson 1 spearman 1 kendall 0.75 std 1.34 0.8)\n",
    "# 0.0302914 (740 pearson 1 spearman 1 kendall 0.75 std 1.335 0.8)\n",
    "# 0.0302682 (740 pearson 1 spearman 1 kendall 0.75 std 1.32 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = DF()\n",
    "sub['name'] = test_ID\n",
    "sub['score'] = DF((mean_ans1+mean_ans2+mean_ans3)/3)\n",
    "DF(sub).to_csv('Feature 3 name mean1.5777 0.5222 std xgb lgb svr.csv',header=False,index=False)\n",
    "# DF(ans3).to_csv('Feature 3 name xgb Only.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADD :  7   3.0240599544\n",
      "SVR :  7   3.10355172148\n",
      "SVR :  9   3.05292171764\n",
      "ADD :  10   3.01900028117\n",
      "SVR :  10   3.13109899633\n",
      "SVR :  14   3.06771881057\n",
      "ADD :  16   3.12366177819\n",
      "SVR :  16   3.21755619676\n",
      "LGB : 16   3.10900770341\n",
      "XGB : 16   3.04442\n",
      "SVR :  18   3.04090361099\n",
      "ADD :  21   3.00156188671\n",
      "XGB : 21   3.02368\n",
      "SVR :  29   3.03517856498\n",
      "SVR :  32   3.01876890211\n",
      "ADD :  37   3.03670288906\n",
      "SVR :  37   3.08347758852\n",
      "XGB : 37   3.02931\n",
      "SVR :  41   3.04023962081\n",
      "ADD :  42   3.03853975097\n",
      "SVR :  42   3.08873967703\n",
      "LGB : 42   3.0638263494\n",
      "SVR :  43   3.00438520939\n",
      "ADD :  47   3.01080848892\n",
      "SVR :  47   3.07249045428\n",
      "XGB : 47   3.00217\n",
      "ADD :  48   3.0870496414\n",
      "SVR :  48   3.13326930739\n",
      "LGB : 48   3.10335540491\n",
      "XGB : 48   3.02452\n",
      "LGB : 76   3.01890831283\n",
      "XGB : 92   3.00066\n",
      "XGB : 95   3.04729\n",
      "SVR :  118   3.03261623574\n",
      "ADD :  133   3.05409213822\n",
      "SVR :  133   3.0193594174\n",
      "LGB : 133   3.03323205312\n",
      "XGB : 133   3.10968\n",
      "LGB : 162   3.02078644277\n",
      "LGB : 174   3.00592914418\n",
      "ADD :  185   3.00705574935\n",
      "LGB : 185   3.03404605308\n",
      "XGB : 185   3.05027\n",
      "LGB : 206   3.0133948377\n",
      "XGB : 206   3.01261\n",
      "ADD :  208   3.01097689313\n",
      "LGB : 208   3.05947848271\n",
      "XGB : 208   3.07634\n",
      "ADD :  238   3.00774413542\n",
      "LGB : 238   3.01956647805\n",
      "XGB : 238   3.03181\n",
      "ADD :  250   3.01705747924\n",
      "LGB : 250   3.05747381296\n",
      "XGB : 250   3.03233\n",
      "ADD :  251   3.03451567384\n",
      "LGB : 251   3.13265642033\n",
      "XGB : 251   3.06137\n",
      "XGB : 252   3.04314\n",
      "LGB : 260   3.02551169281\n",
      "SVR :  275   3.02236541476\n",
      "LGB : 287   3.00507388009\n",
      "LGB : 290   3.01414806959\n"
     ]
    }
   ],
   "source": [
    "mean_add = ((mean_ans1+mean_ans2+mean_ans3)/3)\n",
    "for i in range(len(mean_add)):\n",
    "    if mean_add[i]>=3:\n",
    "        print('ADD : ',i,' ',mean_add[i])\n",
    "    if mean_ans1[i]>=3:\n",
    "        print('SVR : ',i,' ',mean_ans1[i])\n",
    "    if mean_ans2[i]>=3:\n",
    "        print('LGB :', i,' ',mean_ans2[i])\n",
    "    if mean_ans3[i]>=3:\n",
    "        print('XGB :', i,' ',mean_ans3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_fuck = [i for i in train_data.columns if i not in feature_3_name]\n",
    "DF(what_fuck).to_csv('fuck.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB : 6   3.04726384839\n",
      "ADD :  7   3.02694700237\n",
      "SVR :  7   3.04560006934\n",
      "LGB : 7   3.06410818249\n",
      "ADD :  10   3.02392959157\n",
      "SVR :  10   3.04819388493\n",
      "LGB : 10   3.00607326998\n",
      "XGB : 10   3.01752\n",
      "ADD :  14   3.00242548132\n",
      "SVR :  14   3.03974850987\n",
      "ADD :  16   3.14156141278\n",
      "SVR :  16   3.11577898936\n",
      "LGB : 16   3.18083870922\n",
      "XGB : 16   3.12807\n",
      "LGB : 17   3.02769619976\n",
      "SVR :  18   3.00644249485\n",
      "XGB : 21   3.08076\n",
      "SVR :  29   3.02775380497\n",
      "LGB : 32   3.01301703403\n",
      "ADD :  37   3.03482686849\n",
      "LGB : 37   3.05450453078\n",
      "XGB : 37   3.07888\n",
      "SVR :  41   3.01257861063\n",
      "LGB : 41   3.0023187936\n",
      "ADD :  42   3.03350640829\n",
      "SVR :  42   3.04875788908\n",
      "LGB : 42   3.08797497218\n",
      "ADD :  47   3.04625157218\n",
      "SVR :  47   3.04690716926\n",
      "LGB : 47   3.02127254842\n",
      "XGB : 47   3.07057\n",
      "ADD :  48   3.03192045687\n",
      "SVR :  48   3.04134035141\n",
      "LGB : 48   3.04908521139\n",
      "XGB : 48   3.00534\n",
      "LGB : 49   3.01392206026\n",
      "XGB : 49   3.01972\n",
      "SVR :  118   3.00650386135\n",
      "LGB : 133   3.0276416079\n",
      "XGB : 133   3.01531\n",
      "XGB : 185   3.00172\n",
      "LGB : 189   3.01310676076\n",
      "LGB : 193   3.01298714183\n",
      "LGB : 202   3.00535661454\n",
      "LGB : 204   3.01725022704\n",
      "LGB : 238   3.05402849189\n",
      "LGB : 250   3.03933291578\n",
      "ADD :  251   3.00827663045\n",
      "LGB : 251   3.10094527635\n",
      "XGB : 251   3.03182\n",
      "LGB : 260   3.00996069544\n",
      "LGB : 273   3.01338981069\n"
     ]
    }
   ],
   "source": [
    "std_add = ((std_ans1+std_ans2+std_ans3)/3)\n",
    "for i in range(len(std_add)):\n",
    "    if std_add[i]>=3:\n",
    "        print('ADD : ',i,' ',std_add[i])\n",
    "    if std_ans1[i]>=3:\n",
    "        print('SVR : ',i,' ',std_ans1[i])\n",
    "    if std_ans2[i]>=3:\n",
    "        print('LGB :', i,' ',std_ans2[i])\n",
    "    if std_ans3[i]>=3:\n",
    "        print('XGB :', i,' ',std_ans3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desAns(ans1,ans2,ans3,add):\n",
    "    print(pd.concat([DF(ans1,columns=['SVR']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]),DF(ans2,columns=['LGB']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]),DF(ans3,columns=['XGB']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]),DF((ans1+ans2+ans3)/3,columns=['ADD']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99])],axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              SVR         LGB         XGB         ADD\n",
      "count  300.000000  300.000000  300.000000  300.000000\n",
      "mean     2.809681    2.824701    2.778185    2.804189\n",
      "std      0.087067    0.108531    0.109866    0.093325\n",
      "min      2.612255    2.535394    2.526080    2.574039\n",
      "10%      2.700420    2.691435    2.646861    2.689175\n",
      "50%      2.804201    2.818766    2.763465    2.793054\n",
      "90%      2.913160    2.971245    2.928798    2.922621\n",
      "91%      2.921416    2.972914    2.939297    2.929384\n",
      "92%      2.931302    2.981690    2.950346    2.943072\n",
      "93%      2.937990    3.002531    2.961739    2.954340\n",
      "94%      2.954624    3.010142    2.966211    2.962544\n",
      "95%      2.965984    3.013121    2.971600    2.971527\n",
      "96%      2.985542    3.017411    2.990682    2.988884\n",
      "97%      3.006686    3.028045    3.001831    2.998575\n",
      "98%      3.039780    3.049184    3.017566    3.023990\n",
      "99%      3.046920    3.064347    3.070658    3.033520\n",
      "max      3.115779    3.180839    3.128067    3.141561\n",
      "              SVR         LGB         XGB         ADD\n",
      "count  300.000000  300.000000  300.000000  300.000000\n",
      "mean     2.814269    2.821936    2.809334    2.815179\n",
      "std      0.111967    0.106264    0.108949    0.100558\n",
      "min      2.544620    2.515530    2.485363    2.533159\n",
      "10%      2.680450    2.699062    2.678398    2.695075\n",
      "50%      2.812127    2.804708    2.795720    2.803763\n",
      "90%      2.953164    2.974292    2.962038    2.951913\n",
      "91%      2.958825    2.977692    2.966226    2.953896\n",
      "92%      2.964854    2.983105    2.971722    2.956318\n",
      "93%      2.971447    2.984483    2.982392    2.966441\n",
      "94%      2.983082    2.997198    2.990094    2.976734\n",
      "95%      3.018798    3.005117    2.997983    2.987815\n",
      "96%      3.032719    3.014338    3.013054    3.007083\n",
      "97%      3.041264    3.020928    3.029384    3.011159\n",
      "98%      3.072710    3.034515    3.043163    3.024269\n",
      "99%      3.103827    3.064222    3.050382    3.038695\n",
      "max      3.217556    3.132656    3.109685    3.123662\n"
     ]
    }
   ],
   "source": [
    "desAns(std_ans1,std_ans2,std_ans3,std_add)\n",
    "desAns(mean_ans1,mean_ans2,mean_ans3,mean_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_ans = SVR().fit(X_train_kendall[feature_3_name],train_label).predict(X_test_kendall[feature_3_name])\n",
    "sub = DF()\n",
    "sub['ID'] = test_ID\n",
    "sub['Pre'] = svr_ans\n",
    "sub.to_csv(\"submission_data.csv\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVR</th>\n",
       "      <th>LGB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>ADD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.817451</td>\n",
       "      <td>2.785387</td>\n",
       "      <td>2.724503</td>\n",
       "      <td>2.775781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.089690</td>\n",
       "      <td>0.098658</td>\n",
       "      <td>0.134754</td>\n",
       "      <td>0.093551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.570894</td>\n",
       "      <td>2.523077</td>\n",
       "      <td>2.271342</td>\n",
       "      <td>2.513323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>2.708525</td>\n",
       "      <td>2.665416</td>\n",
       "      <td>2.539583</td>\n",
       "      <td>2.653037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.819294</td>\n",
       "      <td>2.781165</td>\n",
       "      <td>2.736069</td>\n",
       "      <td>2.775878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>2.938971</td>\n",
       "      <td>2.907456</td>\n",
       "      <td>2.883889</td>\n",
       "      <td>2.887922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91%</th>\n",
       "      <td>2.941462</td>\n",
       "      <td>2.918407</td>\n",
       "      <td>2.888655</td>\n",
       "      <td>2.892893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92%</th>\n",
       "      <td>2.953184</td>\n",
       "      <td>2.920510</td>\n",
       "      <td>2.896716</td>\n",
       "      <td>2.898137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93%</th>\n",
       "      <td>2.963250</td>\n",
       "      <td>2.927080</td>\n",
       "      <td>2.906653</td>\n",
       "      <td>2.906114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94%</th>\n",
       "      <td>2.968463</td>\n",
       "      <td>2.930982</td>\n",
       "      <td>2.917455</td>\n",
       "      <td>2.917337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>2.974740</td>\n",
       "      <td>2.943026</td>\n",
       "      <td>2.919228</td>\n",
       "      <td>2.921114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96%</th>\n",
       "      <td>2.980558</td>\n",
       "      <td>2.963902</td>\n",
       "      <td>2.924056</td>\n",
       "      <td>2.935958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97%</th>\n",
       "      <td>2.990774</td>\n",
       "      <td>2.973770</td>\n",
       "      <td>2.958384</td>\n",
       "      <td>2.950097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98%</th>\n",
       "      <td>2.996875</td>\n",
       "      <td>3.015095</td>\n",
       "      <td>2.969858</td>\n",
       "      <td>2.983854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>3.020156</td>\n",
       "      <td>3.072497</td>\n",
       "      <td>3.032073</td>\n",
       "      <td>3.024910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.191761</td>\n",
       "      <td>3.092621</td>\n",
       "      <td>3.122592</td>\n",
       "      <td>3.126637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SVR         LGB         XGB         ADD\n",
       "count  300.000000  300.000000  300.000000  300.000000\n",
       "mean     2.817451    2.785387    2.724503    2.775781\n",
       "std      0.089690    0.098658    0.134754    0.093551\n",
       "min      2.570894    2.523077    2.271342    2.513323\n",
       "10%      2.708525    2.665416    2.539583    2.653037\n",
       "50%      2.819294    2.781165    2.736069    2.775878\n",
       "90%      2.938971    2.907456    2.883889    2.887922\n",
       "91%      2.941462    2.918407    2.888655    2.892893\n",
       "92%      2.953184    2.920510    2.896716    2.898137\n",
       "93%      2.963250    2.927080    2.906653    2.906114\n",
       "94%      2.968463    2.930982    2.917455    2.917337\n",
       "95%      2.974740    2.943026    2.919228    2.921114\n",
       "96%      2.980558    2.963902    2.924056    2.935958\n",
       "97%      2.990774    2.973770    2.958384    2.950097\n",
       "98%      2.996875    3.015095    2.969858    2.983854\n",
       "99%      3.020156    3.072497    3.032073    3.024910\n",
       "max      3.191761    3.092621    3.122592    3.126637"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans1 = SVR(C=1.2).fit(X_train_kendall_mean,train_label).predict(X_test_kendall_mean)\n",
    "ans2 = lgb.LGBMRegressor(n_estimators=130,max_depth=7).fit(X_train_kendall_mean,train_label).predict(X_test_kendall_mean)\n",
    "ans3 = xgb.XGBRegressor().fit(X_train_kendall_mean,train_label).predict(X_test_kendall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVR</th>\n",
       "      <th>LGB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>ADD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.898668</td>\n",
       "      <td>2.795568</td>\n",
       "      <td>2.765049</td>\n",
       "      <td>2.819761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.068496</td>\n",
       "      <td>0.084780</td>\n",
       "      <td>0.095704</td>\n",
       "      <td>0.067029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.732813</td>\n",
       "      <td>2.430044</td>\n",
       "      <td>2.543682</td>\n",
       "      <td>2.607318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>2.814893</td>\n",
       "      <td>2.699580</td>\n",
       "      <td>2.658447</td>\n",
       "      <td>2.741042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.896077</td>\n",
       "      <td>2.796060</td>\n",
       "      <td>2.752173</td>\n",
       "      <td>2.815953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>2.994051</td>\n",
       "      <td>2.894394</td>\n",
       "      <td>2.909182</td>\n",
       "      <td>2.905595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91%</th>\n",
       "      <td>2.996499</td>\n",
       "      <td>2.898805</td>\n",
       "      <td>2.915988</td>\n",
       "      <td>2.909052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92%</th>\n",
       "      <td>2.998601</td>\n",
       "      <td>2.904494</td>\n",
       "      <td>2.919918</td>\n",
       "      <td>2.912658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93%</th>\n",
       "      <td>3.001434</td>\n",
       "      <td>2.907520</td>\n",
       "      <td>2.924130</td>\n",
       "      <td>2.917326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94%</th>\n",
       "      <td>3.006991</td>\n",
       "      <td>2.911083</td>\n",
       "      <td>2.934896</td>\n",
       "      <td>2.922528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>3.009587</td>\n",
       "      <td>2.918338</td>\n",
       "      <td>2.945396</td>\n",
       "      <td>2.941574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96%</th>\n",
       "      <td>3.022426</td>\n",
       "      <td>2.925637</td>\n",
       "      <td>2.966718</td>\n",
       "      <td>2.946256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97%</th>\n",
       "      <td>3.028017</td>\n",
       "      <td>2.928132</td>\n",
       "      <td>2.978695</td>\n",
       "      <td>2.963680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98%</th>\n",
       "      <td>3.037968</td>\n",
       "      <td>2.956120</td>\n",
       "      <td>3.012924</td>\n",
       "      <td>2.972489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>3.048254</td>\n",
       "      <td>2.972843</td>\n",
       "      <td>3.044990</td>\n",
       "      <td>2.991298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.099377</td>\n",
       "      <td>3.006553</td>\n",
       "      <td>3.073077</td>\n",
       "      <td>3.039664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SVR         LGB         XGB         ADD\n",
       "count  300.000000  300.000000  300.000000  300.000000\n",
       "mean     2.898668    2.795568    2.765049    2.819761\n",
       "std      0.068496    0.084780    0.095704    0.067029\n",
       "min      2.732813    2.430044    2.543682    2.607318\n",
       "10%      2.814893    2.699580    2.658447    2.741042\n",
       "50%      2.896077    2.796060    2.752173    2.815953\n",
       "90%      2.994051    2.894394    2.909182    2.905595\n",
       "91%      2.996499    2.898805    2.915988    2.909052\n",
       "92%      2.998601    2.904494    2.919918    2.912658\n",
       "93%      3.001434    2.907520    2.924130    2.917326\n",
       "94%      3.006991    2.911083    2.934896    2.922528\n",
       "95%      3.009587    2.918338    2.945396    2.941574\n",
       "96%      3.022426    2.925637    2.966718    2.946256\n",
       "97%      3.028017    2.928132    2.978695    2.963680\n",
       "98%      3.037968    2.956120    3.012924    2.972489\n",
       "99%      3.048254    2.972843    3.044990    2.991298\n",
       "max      3.099377    3.006553    3.073077    3.039664"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([DF(ans1,columns=['SVR']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]),DF(ans2,columns=['LGB']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]),DF(ans3,columns=['XGB']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]),DF((ans1+ans2+ans3)/3,columns=['ADD']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans1 = SVR(C=1.2).fit(X_train_kendall_mean,train_label).predict(X_test_kendall_mean)\n",
    "ans2 = lgb.LGBMRegressor(n_estimators=130,max_depth=7).fit(X_train_kendall_mean,train_label).predict(X_test_kendall_mean)\n",
    "ans3 = xgb.XGBRegressor().fit(X_train_kendall_mean,train_label).predict(X_test_kendall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVR</th>\n",
       "      <th>LGB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>ADD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.843378</td>\n",
       "      <td>2.811929</td>\n",
       "      <td>2.807213</td>\n",
       "      <td>2.820840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.102396</td>\n",
       "      <td>0.100875</td>\n",
       "      <td>0.118175</td>\n",
       "      <td>0.095551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.588346</td>\n",
       "      <td>2.509291</td>\n",
       "      <td>2.507654</td>\n",
       "      <td>2.593092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>2.725613</td>\n",
       "      <td>2.701835</td>\n",
       "      <td>2.652357</td>\n",
       "      <td>2.693816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.839751</td>\n",
       "      <td>2.804526</td>\n",
       "      <td>2.812141</td>\n",
       "      <td>2.812987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>2.987056</td>\n",
       "      <td>2.938544</td>\n",
       "      <td>2.962383</td>\n",
       "      <td>2.941915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91%</th>\n",
       "      <td>2.989472</td>\n",
       "      <td>2.941528</td>\n",
       "      <td>2.965093</td>\n",
       "      <td>2.952744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92%</th>\n",
       "      <td>2.991064</td>\n",
       "      <td>2.950479</td>\n",
       "      <td>2.971146</td>\n",
       "      <td>2.956526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93%</th>\n",
       "      <td>2.997044</td>\n",
       "      <td>2.974401</td>\n",
       "      <td>2.978269</td>\n",
       "      <td>2.958362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94%</th>\n",
       "      <td>3.006244</td>\n",
       "      <td>2.976179</td>\n",
       "      <td>2.989080</td>\n",
       "      <td>2.963451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>3.013615</td>\n",
       "      <td>2.979959</td>\n",
       "      <td>2.998279</td>\n",
       "      <td>2.966091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96%</th>\n",
       "      <td>3.024196</td>\n",
       "      <td>2.985080</td>\n",
       "      <td>3.003749</td>\n",
       "      <td>2.987429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97%</th>\n",
       "      <td>3.034639</td>\n",
       "      <td>2.999906</td>\n",
       "      <td>3.014626</td>\n",
       "      <td>2.996142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98%</th>\n",
       "      <td>3.048962</td>\n",
       "      <td>3.010121</td>\n",
       "      <td>3.037420</td>\n",
       "      <td>3.013010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>3.084137</td>\n",
       "      <td>3.044319</td>\n",
       "      <td>3.054148</td>\n",
       "      <td>3.029457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.133320</td>\n",
       "      <td>3.079774</td>\n",
       "      <td>3.137400</td>\n",
       "      <td>3.094996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SVR         LGB         XGB         ADD\n",
       "count  300.000000  300.000000  300.000000  300.000000\n",
       "mean     2.843378    2.811929    2.807213    2.820840\n",
       "std      0.102396    0.100875    0.118175    0.095551\n",
       "min      2.588346    2.509291    2.507654    2.593092\n",
       "10%      2.725613    2.701835    2.652357    2.693816\n",
       "50%      2.839751    2.804526    2.812141    2.812987\n",
       "90%      2.987056    2.938544    2.962383    2.941915\n",
       "91%      2.989472    2.941528    2.965093    2.952744\n",
       "92%      2.991064    2.950479    2.971146    2.956526\n",
       "93%      2.997044    2.974401    2.978269    2.958362\n",
       "94%      3.006244    2.976179    2.989080    2.963451\n",
       "95%      3.013615    2.979959    2.998279    2.966091\n",
       "96%      3.024196    2.985080    3.003749    2.987429\n",
       "97%      3.034639    2.999906    3.014626    2.996142\n",
       "98%      3.048962    3.010121    3.037420    3.013010\n",
       "99%      3.084137    3.044319    3.054148    3.029457\n",
       "max      3.133320    3.079774    3.137400    3.094996"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([DF(ans1,columns=['SVR']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]),DF(ans2,columns=['LGB']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]),DF(ans3,columns=['XGB']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]),DF((ans1+ans2+ans3)/3,columns=['ADD']).describe(percentiles=[0.1,0.90,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.6463232 ,  2.67987394,  2.66321397,  2.78962302,  2.86273813,\n",
       "        2.72562814,  2.93477535,  2.97770381,  2.86271167,  2.84516525,\n",
       "        3.01595235,  2.69509339,  2.83497882,  2.9220016 ,  3.04489899,\n",
       "        3.01286268,  3.07307673,  3.01073194,  3.01074529,  2.9714601 ,\n",
       "        2.89741254,  3.06908393,  2.93679333,  2.82359719,  2.7377696 ,\n",
       "        2.66761804,  2.84036207,  2.75189042,  2.64864159,  2.80065966,\n",
       "        2.78830004,  2.64973783,  2.82461429,  2.76032948,  2.79598904,\n",
       "        2.75257134,  2.76281476,  3.05398202,  2.97589588,  2.89113855,\n",
       "        2.88025975,  2.90897298,  2.92655253,  2.91607666,  2.8762486 ,\n",
       "        2.89420462,  2.92321229,  3.03089046,  2.94776964,  2.94527078,\n",
       "        2.73654985,  2.6606555 ,  2.72935724,  2.75817418,  2.66871595,\n",
       "        2.67594409,  2.71328974,  2.72655988,  2.76547885,  2.74045324,\n",
       "        2.79222035,  2.766927  ,  2.74810195,  2.77812028,  2.81750727,\n",
       "        2.71799779,  2.73212266,  2.7463758 ,  2.77535653,  2.76004815,\n",
       "        2.77759624,  2.73427701,  2.73527813,  2.62881303,  2.75084066,\n",
       "        2.73193359,  2.82038903,  2.80695391,  2.78787947,  2.77189422,\n",
       "        2.69484925,  2.74776888,  2.71125054,  2.77053547,  2.68785644,\n",
       "        2.74102092,  2.62572622,  2.58582139,  2.6082325 ,  2.8375597 ,\n",
       "        2.81968832,  2.86255455,  2.73006892,  2.78325772,  2.78509283,\n",
       "        2.73190904,  2.74207854,  2.76054382,  2.69432497,  2.7561605 ,\n",
       "        2.66054559,  2.71861815,  2.80065417,  2.74950981,  2.72221303,\n",
       "        2.78928137,  2.78190088,  2.70688534,  2.74181342,  2.72413898,\n",
       "        2.6989696 ,  2.73112464,  2.78022456,  2.8302474 ,  2.68675661,\n",
       "        2.7017014 ,  2.72138548,  2.80449653,  2.79466629,  2.70496488,\n",
       "        2.54774141,  2.58564019,  2.70944166,  2.78361845,  2.80661631,\n",
       "        2.84084988,  2.74734521,  2.80582428,  2.64735293,  2.73876882,\n",
       "        2.68558574,  2.70027947,  2.78949666,  2.94494653,  2.67271805,\n",
       "        2.67923903,  2.63260245,  2.69794559,  2.675524  ,  2.72135091,\n",
       "        2.72121859,  2.68578219,  2.73008513,  2.63759398,  2.73858476,\n",
       "        2.69706106,  2.79953933,  2.82649779,  2.82644796,  2.64123726,\n",
       "        2.62480617,  2.6252532 ,  2.64474559,  2.73252487,  2.68825006,\n",
       "        2.7134769 ,  2.77904987,  2.71327758,  2.75034285,  2.92394805,\n",
       "        2.83874941,  2.69542456,  2.72958851,  2.8174181 ,  2.74726248,\n",
       "        2.77074695,  2.75705194,  2.63415861,  2.76634288,  2.68611312,\n",
       "        2.69481874,  2.76849937,  2.72891045,  2.65285063,  2.63675451,\n",
       "        2.59643173,  2.61084533,  2.69681501,  2.68715048,  2.80163383,\n",
       "        2.78682733,  2.7296474 ,  2.86892247,  2.80289721,  2.81058192,\n",
       "        2.87408543,  2.6937952 ,  2.66022778,  2.58341122,  2.77357769,\n",
       "        2.71015429,  2.77347755,  2.67016602,  2.68508983,  2.66750431,\n",
       "        2.62725067,  2.77128363,  2.68197989,  2.69760823,  2.5436821 ,\n",
       "        2.64348793,  2.73420572,  2.71029711,  2.73054147,  2.7081759 ,\n",
       "        2.73912144,  2.79395914,  2.78137136,  2.8638773 ,  2.66298223,\n",
       "        2.81376338,  2.7465775 ,  2.87517762,  2.83171105,  2.73859286,\n",
       "        2.78148437,  2.80067849,  2.74269032,  2.80109715,  2.72356057,\n",
       "        2.91106486,  2.70382285,  2.77188778,  2.80270028,  2.68499374,\n",
       "        2.92834401,  2.5462184 ,  2.67743897,  2.9113028 ,  2.91597915,\n",
       "        2.96546936,  2.76558399,  2.76363611,  2.71697354,  2.69685411,\n",
       "        2.70920277,  2.80585361,  2.6712451 ,  2.74589872,  2.77701163,\n",
       "        2.76161742,  2.82776856,  2.83993888,  2.83448052,  2.78266191,\n",
       "        2.79904246,  2.88219476,  2.78795886,  2.8495059 ,  2.70082712,\n",
       "        2.77552557,  2.91804624,  2.79695129,  2.75043678,  2.72714567,\n",
       "        2.69173288,  2.70660615,  2.75245619,  2.73663282,  2.63566804,\n",
       "        2.78852344,  2.69875002,  2.75548553,  2.63521004,  2.75803733,\n",
       "        2.89182043,  2.74900746,  2.65906906,  2.7288754 ,  2.75000119,\n",
       "        2.66835499,  2.67557096,  2.75640893,  2.71756673,  2.7623446 ,\n",
       "        2.7770133 ,  2.7823782 ,  2.77197766,  2.79675221,  2.73919392,\n",
       "        2.83848667,  2.73878479,  2.83535051,  2.72404051,  2.77792525,\n",
       "        2.79043269,  2.91973639,  2.83435965,  2.72916031,  2.81877518,\n",
       "        2.96652007,  2.772825  ,  2.81959319,  2.73927426,  2.64520955,\n",
       "        2.62314057,  2.68019366,  2.75837708,  2.83540344,  2.76971149], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_ans1 = xgb.XGBRegressor().fit(X_train_kendall,train_label).predict(X_test_kendall)\n",
    "xgb_ans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0284564137565\n",
      "[ 0.0291295   0.02655562  0.01952246  0.02655826  0.04051623]\n",
      "0.0261663475717\n",
      "[ 0.02887647  0.02484296  0.01937923  0.02249533  0.03523774]\n"
     ]
    }
   ],
   "source": [
    "cv_result = cv(xgb.XGBRegressor(),X_train_kendall[feature_3_name],train_label,cv=10,n_jobs=4,scoring='mean_squared_error')\n",
    "cv_result = -cv_result\n",
    "print(cv_result.mean())\n",
    "print(cv_result)\n",
    "\n",
    "cv_result = cv(xgb.XGBRegressor(),X_train_kendall,train_label,cv=10,n_jobs=4,scoring='mean_squared_error')\n",
    "cv_result = -cv_result\n",
    "print(cv_result.mean())\n",
    "print(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.67622018,  2.66706729,  2.7057116 ,  2.78239155,  2.95038533,\n",
       "        2.68608284,  2.8137598 ,  2.90887713,  2.83242536,  2.90275931,\n",
       "        2.99504948,  2.71590447,  2.89640951,  2.91702771,  3.07464457,\n",
       "        2.99412584,  3.17924523,  3.01733589,  3.00832033,  2.93049216,\n",
       "        2.83157444,  3.0518434 ,  2.8729136 ,  2.75162292,  2.71477509,\n",
       "        2.68378711,  2.76772904,  2.84710979,  2.65080094,  2.64272189,\n",
       "        2.61232781,  2.54777241,  2.75683904,  2.64778495,  2.62309599,\n",
       "        2.64497018,  2.70318484,  3.17285848,  2.9650352 ,  2.76370382,\n",
       "        2.77725577,  2.89457941,  2.8967979 ,  2.93425751,  2.93505287,\n",
       "        2.86752057,  2.93203473,  3.15743351,  3.09490275,  3.02985764,\n",
       "        2.71764469,  2.53160286,  2.62379932,  2.73032689,  2.59350705,\n",
       "        2.57120037,  2.65416646,  2.72101665,  2.71071482,  2.69647217,\n",
       "        2.74430633,  2.75516009,  2.77728248,  2.70009184,  2.7959311 ,\n",
       "        2.71958351,  2.74214482,  2.72635722,  2.74181223,  2.7536087 ,\n",
       "        2.78012443,  2.76769423,  2.73218679,  2.64708686,  2.74664927,\n",
       "        2.72973561,  2.75009823,  2.75534153,  2.7335186 ,  2.71676731,\n",
       "        2.62533355,  2.63658118,  2.72576594,  2.66553378,  2.73074603,\n",
       "        2.70689487,  2.59175992,  2.56553268,  2.54511976,  2.71674824,\n",
       "        2.76347923,  2.74449086,  2.704777  ,  2.65165114,  2.75849414,\n",
       "        2.75384092,  2.75732255,  2.77494311,  2.68308854,  2.66606069,\n",
       "        2.69318914,  2.64409637,  2.64838791,  2.72782421,  2.68989277,\n",
       "        2.75544691,  2.72815394,  2.71354485,  2.71901274,  2.7472949 ,\n",
       "        2.70771337,  2.73700547,  2.7703402 ,  2.8265717 ,  2.71779656,\n",
       "        2.62345099,  2.70358706,  2.79542065,  2.72630692,  2.61388612,\n",
       "        2.57523441,  2.58715105,  2.64968872,  2.77406073,  2.78613877,\n",
       "        2.80029845,  2.70110083,  2.8301053 ,  2.64746094,  2.70289564,\n",
       "        2.58887935,  2.69370198,  2.75496912,  2.88663745,  2.63923001,\n",
       "        2.68644118,  2.62358809,  2.63139915,  2.62590432,  2.68038273,\n",
       "        2.6911242 ,  2.70881581,  2.63508153,  2.64446568,  2.71043396,\n",
       "        2.62293434,  2.74396062,  2.78314185,  2.7754519 ,  2.52268004,\n",
       "        2.61312437,  2.49607468,  2.58237338,  2.7007637 ,  2.5663631 ,\n",
       "        2.68318152,  2.69435406,  2.66611075,  2.6797843 ,  2.73784089,\n",
       "        2.66467357,  2.60605288,  2.59421349,  2.76111436,  2.66412973,\n",
       "        2.73782754,  2.67619944,  2.63686109,  2.72317362,  2.66517591,\n",
       "        2.62900639,  2.70582771,  2.71113563,  2.63657165,  2.5001564 ,\n",
       "        2.55473638,  2.58982325,  2.60341167,  2.61418653,  2.72137046,\n",
       "        2.73689628,  2.70272851,  2.85046744,  2.712152  ,  2.74438405,\n",
       "        2.8138473 ,  2.64236593,  2.60136247,  2.46296263,  2.65470457,\n",
       "        2.58220077,  2.64426351,  2.71215963,  2.68156958,  2.59745431,\n",
       "        2.6269145 ,  2.73984742,  2.62628603,  2.64015007,  2.52595496,\n",
       "        2.64868069,  2.66872144,  2.65737581,  2.67176652,  2.68309188,\n",
       "        2.67013288,  2.68974638,  2.59327769,  2.70854998,  2.61851335,\n",
       "        2.67454982,  2.65168715,  2.74983811,  2.77679563,  2.67094851,\n",
       "        2.72803593,  2.72911191,  2.68153524,  2.69824791,  2.6385076 ,\n",
       "        2.80871534,  2.63869476,  2.70536017,  2.79623556,  2.62575245,\n",
       "        2.88349295,  2.58908105,  2.6578083 ,  2.8611834 ,  2.89761949,\n",
       "        2.90058041,  2.69983006,  2.72101951,  2.6694808 ,  2.68338799,\n",
       "        2.68355775,  2.7647016 ,  2.65097022,  2.73172832,  2.72683334,\n",
       "        2.77427983,  2.8206284 ,  2.76162529,  2.78706169,  2.68952537,\n",
       "        2.74742937,  2.82021785,  2.76435447,  2.86363101,  2.64966059,\n",
       "        2.76810479,  2.74706078,  2.70284271,  2.67290235,  2.71020174,\n",
       "        2.59830832,  2.66337919,  2.72844362,  2.67229891,  2.62577963,\n",
       "        2.66958451,  2.62265277,  2.68767333,  2.58383107,  2.67724895,\n",
       "        2.82159948,  2.6908989 ,  2.57426238,  2.66209483,  2.7137661 ,\n",
       "        2.62258577,  2.65708399,  2.67691445,  2.70400667,  2.69026732,\n",
       "        2.74927044,  2.77537894,  2.72817898,  2.72181392,  2.69504762,\n",
       "        2.79528284,  2.70726776,  2.80098748,  2.67207909,  2.72206426,\n",
       "        2.77682638,  2.86830807,  2.74738407,  2.64512658,  2.74234486,\n",
       "        2.90110922,  2.73125029,  2.76581383,  2.66188478,  2.64059472,\n",
       "        2.57073832,  2.68313742,  2.72834206,  2.82050276,  2.74220061], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_ans = xgb.XGBRegressor().fit(X_train_kendall[feature_3_name],train_label).predict(X_test_kendall[feature_3_name])\n",
    "xgb_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train,cv_valid,cv_train_label,cv_valid_label = train_test_split(X_train_kendall,train_label,test_size=0.15)\n",
    "xgb_train = xgb.DMatrix(cv_train[X_mean_name],cv_train_label)\n",
    "xgb_valid = xgb.DMatrix(cv_valid[X_mean_name],cv_valid_label)\n",
    "xgb_test = xgb.DMatrix(X_test_kendall[X_mean_name])\n",
    "watchlist = [(xgb_train,'train'),(xgb_valid,'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'booster':'gbtree',\n",
    "    'objective': 'reg:linear',\n",
    "    'early_stopping_rounds':10,\n",
    "    'eval_metric': 'rmse',\n",
    "#     'gamma': 1,\n",
    "    'max_depth':5,\n",
    "#     'min_child_weight' : 3,\n",
    "#     'lambda': 50,\n",
    "    # 'alpha' : 0.9,\n",
    "    'eta':0.1,\n",
    "    'seed':1024,\n",
    "    'silent':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2.12495\tvalid-rmse:2.10002\n",
      "[50]\ttrain-rmse:0.049312\tvalid-rmse:0.19871\n",
      "[100]\ttrain-rmse:0.01871\tvalid-rmse:0.19543\n",
      "[150]\ttrain-rmse:0.008545\tvalid-rmse:0.195426\n",
      "[200]\ttrain-rmse:0.003926\tvalid-rmse:0.195225\n",
      "[250]\ttrain-rmse:0.001989\tvalid-rmse:0.195187\n",
      "[300]\ttrain-rmse:0.000966\tvalid-rmse:0.19529\n",
      "[350]\ttrain-rmse:0.000661\tvalid-rmse:0.195299\n",
      "[400]\ttrain-rmse:0.000661\tvalid-rmse:0.195299\n",
      "[450]\ttrain-rmse:0.000661\tvalid-rmse:0.195299\n",
      "[499]\ttrain-rmse:0.000661\tvalid-rmse:0.195299\n"
     ]
    }
   ],
   "source": [
    "model_1 = xgb.train(params, xgb_train, 500 , watchlist, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.039021719141\n"
     ]
    }
   ],
   "source": [
    "xgb_valid_ans = model_1.predict(xgb_valid)\n",
    "print(mse(cv_valid_label,xgb_valid_ans))\n",
    "xgb_all_train = xgb.DMatrix(X_train_kendall[X_mean_name],train_label)\n",
    "model_2 = xgb.train(params, xgb_all_train, 500 , verbose_eval=50)\n",
    "xgb_ans = model_2.predict(xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.69649413,  2.7375916 ,  2.88873485,  2.95361797,  2.79594629,\n",
       "        2.73952015,  2.92479306,  2.76190653,  2.7239036 ,  2.78335014,\n",
       "        2.77897453,  2.9790332 ,  2.86839083,  2.74326733,  2.92728005,\n",
       "        2.77188677,  2.848899  ,  2.75978026,  2.707592  ,  2.73468608,\n",
       "        2.90720488,  2.66169467,  2.71672642,  2.71468707,  2.63260995,\n",
       "        2.95082557,  2.78176576,  2.7388    ,  2.93885645,  2.84889955,\n",
       "        2.79544623,  2.82629458,  2.90720836,  2.80397983,  2.82074406,\n",
       "        2.84962833,  2.98056135,  2.84948232,  2.96122114,  2.88170731,\n",
       "        2.70709783,  2.97615417,  2.79928649,  2.87338816,  2.88439328,\n",
       "        2.89752348,  2.93480365,  2.84185214,  2.7834774 ,  2.87741972,\n",
       "        2.83159254,  2.86058332,  2.91567838,  2.83987362,  2.83488414,\n",
       "        2.89073276,  2.91068932,  2.71020631,  2.85409637,  2.86249309,\n",
       "        2.8361161 ,  2.705979  ,  2.90718832,  2.86929037,  3.01361295,\n",
       "        2.8351724 ,  2.80605041,  2.92598161,  3.03404834,  2.7777495 ,\n",
       "        2.92984257,  2.77758983,  2.77181622,  2.88538717,  2.7336767 ,\n",
       "        2.85919397,  2.74348429,  2.65724957,  2.78282343,  2.91789339,\n",
       "        2.81786684,  2.86671466,  2.93666907,  2.93063135,  2.76931165,\n",
       "        2.9080895 ,  2.80168867,  2.79407545,  2.92848936,  2.94672114,\n",
       "        2.83864   ,  2.94159723,  2.76744558,  2.72045328,  2.76094037,\n",
       "        2.65188487,  2.8640765 ,  2.68728451,  3.06839422,  2.91901122])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_终极融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_svr_3 = SVR(kernel='rbf',C=1).fit(X_train_kendall[feature_3_name],train_label)\n",
    "result_mean_3 = mean_svr_3.predict(X_test_kendall[feature_3_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.62927383,  2.68453228,  2.92281373,  2.91948331,  2.80080521,\n",
       "        2.74943492,  2.97889107,  2.73007744,  2.67186203,  2.69020272,\n",
       "        2.70199254,  2.96393996,  2.83244284,  2.70264182,  2.90883496,\n",
       "        2.70401471,  2.74241936,  2.8001155 ,  2.64121416,  2.65456396,\n",
       "        2.88652375,  2.60646999,  2.66554665,  2.71215218,  2.52660463,\n",
       "        2.96175997,  2.69590623,  2.69780566,  2.94731622,  2.89363356,\n",
       "        2.804284  ,  2.8274824 ,  2.93992623,  2.84228672,  2.89433918,\n",
       "        2.83394309,  2.96865457,  2.88048965,  2.88711168,  2.84915796,\n",
       "        2.75255804,  2.94202287,  2.83262905,  2.8889059 ,  2.83836311,\n",
       "        2.88764293,  2.85353175,  2.81785727,  2.65570214,  2.83170692,\n",
       "        2.76353823,  2.79620967,  2.81443362,  2.76285333,  2.78363061,\n",
       "        2.82440924,  2.96846087,  2.80962849,  2.8789046 ,  2.88699572,\n",
       "        2.79107713,  2.7038499 ,  2.82830302,  2.8273604 ,  2.93536267,\n",
       "        2.77599233,  2.7114182 ,  2.86859331,  2.93372386,  2.74949749,\n",
       "        2.88917809,  2.76859673,  2.73732768,  2.87918105,  2.74246595,\n",
       "        2.88529229,  2.76988501,  2.60487137,  2.81540386,  2.90224516,\n",
       "        2.83106481,  2.89566923,  2.88416938,  2.92261638,  2.82400427,\n",
       "        2.92155484,  2.7566683 ,  2.77435304,  2.97766848,  2.95495836,\n",
       "        2.85303738,  2.9375364 ,  2.78891584,  2.74395806,  2.75617961,\n",
       "        2.68336617,  2.81519538,  2.6904582 ,  3.03822391,  2.92618061])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_mean_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = DF()\n",
    "sub['ID'] = test_ID\n",
    "sub['Pre'] = result_mean_3*0.5+result_final*0.5\n",
    "sub.to_csv(\"submission_final and 3.csv\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8461873043805452"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8201167639166278"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_mean_spearman.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfc = result_mean_3/(result_mean_3.mean()/train_label.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xgb = train_data.T.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3342)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xgb = train_xgb.T\n",
    "train_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in fields TOOL_ID, 210X1, 210X2, 210X3, 210X4, 210X5, 210X6, 210X7, 210X8, 210X9, 210X10, 210X11, 210X12, 210X13, 210X14, 210X15, 210X16, 210X17, 210X18, 210X19, 210X20, 210X21, 210X23, 210X25, 210X26, 210X27, 210X28, 210X29, 210X30, 210X31, 210X32, 210X33, 210X34, 210X35, 210X36, 210X37, 210X38, 210X39, 210X40, 210X41, 210X42, 210X43, 210X44, 210X45, 210X46, 210X47, 210X48, 210X49, 210X50, 210X51, 210X52, 210X53, 210X54, 210X55, 210X56, 210X57, 210X58, 210X59, 210X60, 210X61, 210X62, 210X63, 210X64, 210X65, 210X66, 210X67, 210X68, 210X69, 210X70, 210X71, 210X72, 210X73, 210X74, 210X75, 210X76, 210X77, 210X80, 210X81, 210X82, 210X83, 210X84, 210X85, 210X86, 210X87, 210X88, 210X89, 210X90, 210X91, 210X92, 210X93, 210X94, 210X95, 210X96, 210X97, 210X98, 210X99, 210X100, 210X101, 210X102, 210X104, 210X105, 210X106, 210X107, 210X108, 210X109, 210X110, 210X111, 210X112, 210X113, 210X114, 210X115, 210X116, 210X117, 210X118, 210X119, 210X120, 210X121, 210X122, 210X123, 210X124, 210X125, 210X127, 210X128, 210X129, 210X130, 210X131, 210X132, 210X133, 210X134, 210X135, 210X136, 210X137, 210X138, 210X139, 210X140, 210X141, 210X142, 210X143, 210X144, 210X145, 210X146, 210X147, 210X148, 210X149, 210X150, 210X151, 210X152, 210X153, 210X154, 210X155, 210X156, 210X157, 210X158, 210X159, 210X160, 210X161, 210X162, 210X163, 210X164, 210X165, 210X166, 210X167, 210X168, 210X169, 210X170, 210X171, 210X172, 210X173, 210X174, 210X175, 210X176, 210X177, 210X178, 210X179, 210X180, 210X181, 210X182, 210X183, 210X184, 210X185, 210X186, 210X187, 210X188, 210X189, 210X190, 210X191, 210X192, 210X193, 210X194, 210X195, 210X199, 210X200, 210X201, 210X202, 210X203, 210X206, 210X207, 210X209, 210X210, 210X211, 210X212, 210X214, 210X216, 210X217, 210X218, 210X219, 210X220, 210X221, 210X222, 210X225, 210X226, 210X228, 210X229, 210X230, 210X231, Tool, 220X2, 220X3, 220X4, 220X5, 220X6, 220X7, 220X8, 220X9, 220X10, 220X11, 220X12, 220X13, 220X14, 220X15, 220X18, 220X19, 220X20, 220X21, 220X26, 220X27, 220X28, 220X29, 220X30, 220X31, 220X32, 220X33, 220X53, 220X54, 220X55, 220X58, 220X66, 220X99, 220X107, 220X108, 220X110, 220X112, 220X114, 220X116, 220X118, 220X120, 220X122, 220X124, 220X126, 220X128, 220X130, 220X132, 220X141, 220X142, 220X143, 220X153, 220X155, 220X156, 220X157, 220X159, 220X163, 220X164, 220X165, 220X166, 220X167, 220X168, 220X169, 220X170, 220X171, 220X172, 220X173, 220X174, 220X175, 220X176, 220X177, 220X178, 220X179, 220X180, 220X181, 220X182, 220X183, 220X184, 220X185, 220X186, 220X187, 220X188, 220X189, 220X190, 220X191, 220X192, 220X193, 220X194, 220X195, 220X196, 220X197, 220X198, 220X200, 220X201, 220X204, 220X216, 220X217, 220X218, 220X223, 220X224, 220X237, 220X241, 220X242, 220X247, 220X248, 220X249, 220X260, 220X262, 220X266, 220X269, 220X270, 220X271, 220X272, 220X273, 220X274, 220X275, 220X277, 220X279, 220X281, 220X282, 220X284, 220X286, 220X288, 220X289, 220X290, 220X291, 220X293, 220X294, 220X295, 220X296, 220X297, 220X298, 220X299, 220X300, 220X301, 220X302, 220X303, 220X304, 220X305, 220X306, 220X307, 220X308, 220X309, 220X310, 220X311, 220X312, 220X313, 220X314, 220X315, 220X316, 220X317, 220X318, 220X321, 220X322, 220X323, 220X324, 220X325, 220X326, 220X327, 220X328, 220X329, 220X330, 220X331, 220X332, 220X333, 220X334, 220X335, 220X336, 220X337, 220X338, 220X339, 220X340, 220X341, 220X342, 220X343, 220X344, 220X345, 220X346, 220X347, 220X348, 220X349, 220X350, 220X351, 220X352, 220X353, 220X354, 220X355, 220X356, 220X357, 220X358, 220X359, 220X360, 220X361, 220X362, 220X363, 220X364, 220X365, 220X366, 220X367, 220X368, 220X369, 220X370, 220X371, 220X372, 220X373, 220X374, 220X375, 220X376, 220X377, 220X378, 220X379, 220X380, 220X381, 220X382, 220X383, 220X384, 220X385, 220X386, 220X387, 220X388, 220X389, 220X390, 220X392, 220X393, 220X394, 220X395, 220X396, 220X397, 220X398, 220X399, 220X400, 220X402, 220X403, 220X404, 220X405, 220X406, 220X407, 220X408, 220X409, 220X410, 220X411, 220X412, 220X413, 220X414, 220X415, 220X416, 220X417, 220X419, 220X420, 220X421, 220X422, 220X423, 220X424, 220X425, 220X427, 220X428, 220X429, 220X430, 220X431, 220X433, 220X434, 220X435, 220X437, 220X438, 220X439, 220X440, 220X441, 220X442, 220X443, 220X444, 220X445, 220X446, 220X447, 220X448, 220X449, 220X450, 220X451, 220X452, 220X454, 220X456, 220X457, 220X458, 220X459, 220X461, 220X462, 220X463, 220X465, 220X467, 220X468, 220X469, 220X470, 220X471, 220X472, 220X474, 220X475, 220X476, 220X477, 220X478, 220X479, 220X480, 220X481, 220X482, 220X483, 220X484, 220X485, 220X486, 220X487, 220X488, 220X489, 220X490, 220X491, 220X492, 220X493, 220X494, 220X495, 220X496, 220X497, 220X498, 220X499, 220X500, 220X501, 220X502, 220X503, 220X504, 220X505, 220X506, 220X507, 220X508, 220X509, 220X510, 220X512, 220X514, 220X515, 220X516, 220X517, 220X518, 220X520, 220X521, 220X522, 220X523, 220X524, 220X526, 220X528, 220X529, 220X530, 220X531, 220X532, 220X533, 220X535, 220X539, 220X540, 220X541, 220X549, 220X550, 220X551, 220X554, 220X557, 220X570, 220X571, TOOL_ID (#1), 300X1, 300X5, 300X8, 300X11, 300X12, 300X15, 300X16, 300X17, 300X21, TOOL_ID (#2), 310X2, 310X3, 310X4, 310X5, 310X6, 310X8, 310X9, 310X10, 310X11, 310X12, 310X13, 310X14, 310X15, 310X19, 310X20, 310X21, 310X22, 310X23, 310X24, 310X27, 310X28, 310X29, 310X30, 310X31, 310X32, 310X33, 310X34, 310X36, 310X37, 310X38, 310X42, 310X43, 310X44, 310X88, 310X96, 310X97, 310X99, 310X101, 310X103, 310X105, 310X107, 310X109, 310X111, 310X113, 310X115, 310X117, 310X119, 310X121, 310X130, 310X131, 310X132, 310X147, 310X148, 310X149, 310X150, 310X151, 310X152, 310X153, 310X154, 310X155, 310X156, 310X157, 310X158, 310X159, 310X160, 310X161, 310X162, 310X163, 310X164, 310X165, 310X166, 310X167, 310X168, 310X169, 310X170, 310X171, 310X172, 310X173, 310X174, 310X175, 310X176, 310X177, 310X178, 310X179, 310X180, 310X181, 310X188, 310X200, 310X201, 310X202, 310X206, 310X207, TOOL_ID (#3), 311X1, 311X4, 311X7, 311X8, 311X9, 311X10, 311X11, 311X12, 311X15, 311X16, 311X17, 311X18, 311X19, 311X20, 311X21, 311X22, 311X23, 311X27, 311X28, 311X33, 311X39, 311X41, 311X42, 311X43, 311X44, 311X45, 311X47, 311X48, 311X50, 311X55, 311X56, 311X57, 311X58, 311X59, 311X60, 311X61, 311X62, 311X63, 311X64, 311X66, 311X67, 311X68, 311X69, 311X70, 311X71, 311X72, 311X73, 311X74, 311X75, 311X76, 311X77, 311X79, 311X80, 311X82, 311X83, 311X85, 311X86, 311X87, 311X90, 311X91, 311X94, 311X95, 311X96, 311X97, 311X98, 311X101, 311X102, 311X103, 311X104, 311X105, 311X106, 311X107, 311X108, 311X109, 311X110, 311X111, 311X112, 311X113, 311X114, 311X115, 311X116, 311X117, 311X118, 311X130, 311X154, 311X155, 311X156, 311X157, 311X158, 311X159, 311X160, 311X161, 311X162, 311X164, 311X165, 311X168, 311X170, 311X171, 311X173, 311X174, 311X175, 311X178, 311X179, 311X182, 311X183, 311X184, 311X185, 311X191, 311X192, 311X193, 311X195, 311X196, 311X197, 311X199, 311X200, 311X201, 311X202, 311X203, 311X204, 311X206, 311X217, 311X218, 311X219, 311X220, 311X221, 311X222, 311X223, 311X224, 311X225, 261X226, 261X227, 261X228, 261X229, 261X230, 261X231, 261X232, 261X233, 261X234, 261X235, 261X236, 261X237, 261X238, 261X239, 261X240, 261X241, 261X242, 261X244, 261X245, 261X246, 261X247, 261X248, 261X249, 261X250, 261X251, 261X252, 261X254, 261X255, 261X256, 261X257, 261X258, 261X259, 261X260, 261X261, 261X262, 261X264, 261X265, 261X266, 261X267, 261X268, 261X269, 261X270, 261X271, 261X272, 261X274, 261X275, 261X276, 261X277, 261X278, 261X279, 261X280, 261X281, 261X282, 261X284, 261X285, 261X286, 261X287, 261X288, 261X289, 261X290, 261X291, 261X292, 261X294, 261X295, 261X296, 261X310, 261X315, 261X318, 261X319, 261X321, 261X322, 261X323, 261X324, 261X325, 261X326, 261X328, 261X331, 261X332, 261X333, 261X334, 261X335, 261X336, 261X337, 261X338, 261X340, 261X341, 261X342, 261X343, 261X344, 261X345, 261X346, 261X347, 261X348, 261X351, 261X354, 261X356, 261X357, 261X359, 261X360, 261X361, 261X364, 261X365, 261X368, 261X369, 261X370, 261X371, 261X377, 261X378, 261X379, 261X381, 261X382, 261X383, 261X385, 261X386, 261X387, 261X388, 261X389, 261X390, 261X403, 261X404, 261X405, 261X406, 261X407, 261X408, 261X410, 261X411, 261X412, 261X413, 261X414, 261X415, 261X416, 261X417, 261X418, 261X420, 261X421, 261X422, 261X423, 261X424, 261X425, 261X426, 261X427, 261X428, 261X430, 261X431, 261X432, 261X433, 261X434, 261X435, 261X436, 261X437, 261X438, 261X440, 261X441, 261X442, 261X443, 261X444, 261X445, 261X446, 261X447, 261X448, 261X450, 261X451, 261X452, 261X453, 261X454, 261X455, 261X456, 261X457, 261X458, 261X460, 261X461, 261X462, 261X463, 261X464, 261X465, 261X466, 261X467, 261X468, 261X470, 261X471, 261X472, 261X473, 261X474, 261X475, 261X476, 261X477, 261X478, 261X480, 261X481, 261X482, 261X501, 261X512, 261X513, 261X517, 261X518, 261X519, 261X520, 261X521, 261X522, 261X523, 261X524, 261X526, 261X527, 261X528, 261X529, 261X530, 261X531, 261X532, 261X533, 261X534, 261X536, 261X537, 261X540, 261X542, 261X543, 261X545, 261X546, 261X547, 261X550, 261X551, 261X554, 261X555, 261X556, 261X557, 261X563, 261X564, 261X565, 261X567, 261X568, 261X569, 261X571, 261X572, 261X573, 261X574, 261X575, 261X576, 261X589, 261X590, 261X591, 261X592, 261X593, 261X594, 261X596, 261X597, 261X598, 261X599, 261X600, 261X601, 261X602, 261X603, 261X604, 261X606, 261X607, 261X608, 261X609, 261X610, 261X611, 261X612, 261X613, 261X614, 261X616, 261X617, 261X618, 261X619, 261X620, 261X621, 261X622, 261X623, 261X624, 261X626, 261X627, 261X628, 261X629, 261X630, 261X631, 261X632, 261X633, 261X634, 261X636, 261X637, 261X638, 261X639, 261X640, 261X641, 261X642, 261X643, 261X644, 261X646, 261X647, 261X648, 261X649, 261X650, 261X651, 261X652, 261X653, 261X654, 261X656, 261X657, 261X658, 261X659, 261X660, 261X661, 261X662, 261X663, 261X664, 261X666, 261X667, 261X668, 261X687, 261X688, 261X689, 261X693, 261X694, 261X695, 261X696, 261X701, 261X703, 261X704, 261X705, 261X706, 261X707, 261X708, 261X709, 261X710, 261X712, 261X713, 261X714, 261X715, 261X716, 261X717, 261X718, 261X719, 261X720, 261X723, 261X726, 261X728, 261X729, 261X731, 261X732, 261X733, 261X736, 261X737, 261X740, 261X741, 261X742, 261X743, 261X749, 261X750, 261X751, 261X753, 261X754, 261X755, 261X757, 261X758, 261X759, 261X760, 261X761, 261X762, Tool (#1), 312X1, 312X2, 312X3, 312X4, 312X6, 312X7, 312X8, 312X11, 312X12, 312X13, 312X16, 312X17, 312X18, 312X21, 312X22, 312X23, 312X26, 312X27, 312X28, 312X31, 312X32, 312X33, 312X36, 312X37, 312X38, 312X41, 312X42, 312X43, 312X46, 312X47, 312X48, 312X51, 312X52, 312X53, 312X54, 312X55, 312X57, 312X58, 312X59, 312X60, 312X61, 312X63, 312X64, 312X65, 312X66, 312X67, 312X69, 312X70, 312X71, 312X72, 312X73, 312X75, 312X76, 312X77, 312X78, 312X79, 312X81, 312X82, 312X83, 312X84, 312X85, 312X87, 312X88, 312X89, 312X90, 312X91, 312X93, 312X94, 312X95, 312X96, 312X97, 312X99, 312X100, 312X101, 312X102, 312X105, 312X111, 312X112, 312X113, 312X114, 312X115, 312X117, 312X118, 312X119, 312X120, 312X121, 312X123, 312X124, 312X125, 312X126, 312X127, 312X129, 312X130, 312X131, 312X132, 312X133, 312X135, 312X136, 312X137, 312X138, 312X139, 312X141, 312X142, 312X143, 312X144, 312X145, 312X147, 312X153, 312X154, 312X155, 312X159, 312X160, 312X161, 312X162, 312X163, 312X165, 312X166, 312X167, 312X168, 312X169, 312X171, 312X173, 312X174, 312X175, 312X177, 312X180, 312X181, 312X183, 312X185, 312X186, 312X187, 312X189, 312X191, 312X192, 312X193, 312X197, 312X198, 312X199, 312X203, 312X207, 312X208, 312X209, 312X210, 312X211, 312X213, 312X214, 312X215, 312X216, 312X217, 312X219, 312X220, 312X221, 312X222, 312X223, 312X225, 312X227, 312X228, 312X229, 312X231, 312X233, 312X234, 312X235, 312X236, 312X238, 312X239, 312X240, 312X242, 312X244, 312X245, 312X246, 312X249, 312X250, 312X251, 312X253, 312X254, 312X255, 312X256, 312X257, 312X259, 312X260, 312X261, 312X262, 312X263, 312X265, 312X266, 312X267, 312X268, 312X269, 312X272, 312X277, 312X278, 312X279, 312X280, 312X281, 312X283, 312X284, 312X285, 312X286, 312X287, 312X289, 312X290, 312X291, 312X292, 312X293, 312X295, 312X296, 312X297, 312X298, 312X299, 312X303, 312X307, 312X308, 312X309, 312X310, 312X311, 312X313, 312X315, 312X327, 312X331, 312X332, 312X333, 312X334, 312X335, 312X337, 312X338, 312X339, 312X340, 312X341, 312X345, 312X349, 312X350, 312X351, 312X352, 312X353, 312X355, 312X356, 312X357, 312X358, 312X359, 312X361, 312X362, 312X363, 312X364, 312X365, 312X367, 312X373, 312X374, 312X375, 312X376, 312X377, 312X379, 312X380, 312X381, 312X382, 312X383, 312X385, 312X386, 312X387, 312X388, 312X389, 312X421, 312X423, 312X424, 312X425, 312X426, 312X427, 312X428, 312X429, 312X430, 312X435, 312X436, 312X438, 312X439, 312X440, 312X441, 312X442, 312X444, 312X445, 312X446, 312X447, 312X448, 312X456, 312X457, 312X458, 312X459, 312X462, 312X463, 312X464, 312X465, 312X468, 312X469, 312X470, 312X471, 312X474, 312X475, 312X476, 312X477, 312X478, 312X480, 312X481, 312X482, 312X483, 312X486, 312X487, 312X488, 312X489, 312X510, 312X511, 312X516, 312X517, 312X518, 312X519, 312X520, 312X522, 312X523, 312X524, 312X525, 312X528, 312X529, 312X530, 312X531, 312X552, 312X553, 312X554, 312X555, 312X558, 312X559, 312X560, 312X561, 312X564, 312X565, 312X566, 312X567, 312X570, 312X574, 312X576, 312X577, 312X578, 312X579, 312X580, 312X582, 312X583, 312X584, 312X585, 312X586, 312X588, 312X589, 312X590, 312X591, 312X592, 312X594, 312X595, 312X596, 312X597, 312X598, 312X600, 312X601, 312X603, 312X630, 312X631, 312X632, 312X633, 312X634, 312X636, 312X637, 312X638, 312X639, 312X640, 312X642, 312X643, 312X644, 312X645, 312X666, 312X667, 312X668, 312X669, 312X670, 312X672, 312X673, 312X674, 312X675, 312X676, 312X678, 312X679, 312X680, 312X681, 312X682, 312X687, 312X688, 312X690, 312X691, 312X692, 312X693, 312X694, 312X695, 312X696, 312X697, 312X698, 312X699, 312X700, 312X701, 312X702, 312X703, 312X704, 312X710, 312X711, 312X712, 312X713, 312X714, 312X716, 312X717, 312X718, 312X719, 312X720, 312X722, 312X723, 312X724, 312X725, 312X726, 312X728, 312X729, 312X730, 312X731, 312X732, 312X734, 312X735, 312X736, 312X737, 312X738, 312X740, 312X741, 312X742, 312X743, 312X744, 312X746, 312X752, 312X753, 312X754, 312X755, 312X758, 312X759, 312X760, 312X761, 312X762, 312X764, 312X765, 312X766, 312X767, 312X768, 312X770, 312X771, 312X772, 312X773, 312X774, 312X776, 312X777, 312X778, 312X779, 312X780, 312X782, 312X783, 312X784, 312X785, 312X786, 312X788, 312X789, 312X790, 312X791, 312X792, Tool (#2), 330X1, 330X2, 330X3, 330X5, 330X8, 330X9, 330X11, 330X12, 330X21, 330X22, 330X23, 330X25, 330X28, 330X29, 330X31, 330X35, 330X38, 330X41, 330X42, 330X43, 330X45, 330X48, 330X49, 330X51, 330X52, 330X53, 330X55, 330X58, 330X59, 330X61, 330X62, 330X71, 330X72, 330X81, 330X85, 330X88, 330X94, 330X97, 330X98, 330X100, 330X101, 330X102, 330X103, 330X104, 330X105, 330X106, 330X107, 330X108, 330X110, 330X111, 330X112, 330X113, 330X114, 330X118, 330X119, 330X120, 330X121, 330X125, 330X126, 330X127, 330X128, 330X132, 330X133, 330X134, 330X135, 330X139, 330X140, 330X141, 330X142, 330X146, 330X147, 330X148, 330X149, 330X155, 330X157, 330X158, 330X159, 330X165, 330X167, 330X168, 330X169, 330X175, 330X177, 330X178, 330X179, 330X185, 330X188, 330X189, 330X190, 330X191, 330X195, 330X196, 330X197, 330X198, 330X204, 330X206, 330X207, 330X208, 330X214, 330X216, 330X217, 330X218, 330X224, 330X226, 330X227, 330X228, 330X234, 330X236, 330X237, 330X238, 330X244, 330X246, 330X247, 330X248, 330X254, 330X256, 330X257, 330X258, 330X264, 330X266, 330X267, 330X268, 330X274, 330X276, 330X277, 330X278, 330X284, 330X286, 330X287, 330X288, 330X294, 330X296, 330X297, 330X298, 330X302, 330X303, 330X304, 330X305, 330X311, 330X313, 330X314, 330X315, 330X321, 330X323, 330X324, 330X325, 330X331, 330X333, 330X334, 330X335, 330X341, 330X343, 330X344, 330X345, 330X351, 330X353, 330X354, 330X355, 330X361, 330X363, 330X364, 330X365, 330X371, 330X373, 330X374, 330X375, 330X381, 330X383, 330X384, 330X385, 330X391, 330X393, 330X394, 330X395, 330X401, 330X403, 330X404, 330X405, 330X409, 330X410, 330X411, 330X412, 330X418, 330X420, 330X421, 330X422, 330X428, 330X430, 330X431, 330X432, 330X438, 330X440, 330X441, 330X442, 330X448, 330X450, 330X451, 330X452, 330X458, 330X460, 330X461, 330X462, 330X468, 330X470, 330X471, 330X472, 330X478, 330X480, 330X481, 330X482, 330X488, 330X490, 330X491, 330X492, 330X498, 330X501, 330X502, 330X508, 330X510, 330X511, 330X512, 330X516, 330X518, 330X519, 330X525, 330X527, 330X528, 330X529, 330X535, 330X537, 330X538, 330X539, 330X544, 330X546, 330X547, 330X548, 330X552, 330X553, 330X554, 330X555, 330X559, 330X560, 330X561, 330X562, 330X566, 330X567, 330X568, 330X569, 330X573, 330X574, 330X575, 330X576, 330X580, 330X581, 330X582, 330X583, 330X587, 330X588, 330X589, 330X590, 330X594, 330X595, 330X596, 330X597, 330X601, 330X602, 330X603, 330X604, 330X608, 330X609, 330X610, 330X611, 330X615, 330X616, 330X617, 330X624, 330X626, 330X627, 330X629, 330X631, 330X633, 330X634, 330X636, 330X638, 330X641, 330X643, 330X647, 330X669, 330X670, 330X671, 330X673, 330X676, 330X677, 330X689, 330X690, 330X691, 330X696, 330X697, 330X699, 330X700, 330X701, 330X703, 330X706, 330X707, 330X709, 330X710, 330X713, 330X716, 330X717, 330X719, 330X749, 330X769, 330X770, 330X788, 330X789, 330X798, 330X799, 330X808, 330X809, 330X818, 330X878, 330X892, 330X893, 330X894, 330X896, 330X897, 330X899, 330X901, 330X903, 330X906, 330X909, 330X910, 330X912, 330X915, 330X916, 330X919, 330X922, 330X925, 330X929, 330X932, 330X935, 330X939, 330X942, 330X945, 330X949, 330X950, 330X952, 330X955, 330X956, 330X959, 330X969, 330X970, 330X972, 330X975, 330X976, 330X979, 330X989, 330X992, 330X995, 330X999, 330X1009, 330X1010, 330X1016, 330X1019, 330X1022, 330X1025, 330X1029, 330X1030, 330X1031, 330X1033, 330X1034, 330X1036, 330X1053, 330X1076, 330X1077, 330X1079, 330X1082, 330X1083, 330X1086, 330X1089, 330X1092, 330X1096, 330X1099, 330X1109, 330X1112, 330X1126, 330X1129, 330X1132, 330X1146, 330X1156, 330X1166, 330X1172, 330X1173, 330X1174, 330X1176, 330X1177, 330X1179, 330X1181, 330X1186, 330X1187, 330X1188, 330X1190, 330X1191, 330X1193, 330X1200, 330X1202, 330X1204, 330X1207, 330X1214, 330X1226, 330X1228, 330X1231, 330X1248, 330X1250, 330X1252, 330X1255, tool, 340X1, 340X2, 340X3, 340X4, 340X5, 340X6, 340X7, 340X8, 340X9, 340X10, 340X11, 340X13, 340X15, 340X17, 340X18, 340X19, 340X20, 340X21, 340X22, 340X24, 340X25, 340X26, 340X27, 340X28, 340X29, 340X31, 340X33, 340X34, 340X35, 340X36, 340X37, 340X38, 340X39, 340X41, 340X42, 340X43, 340X45, 340X46, 340X47, 340X48, 340X49, 340X51, 340X53, 340X57, 340X59, 340X61, 340X65, 340X67, 340X69, 340X71, 340X73, 340X75, 340X77, 340X79, 340X81, 340X83, 340X85, 340X97, 340X99, 340X101, 340X105, 340X107, 340X108, 340X109, 340X110, 340X113, 340X115, 340X119, 340X121, 340X123, 340X124, 340X125, 340X126, 340X132, 340X133, 340X134, 340X138, 340X139, 340X140, 340X141, 340X143, 340X145, 340X147, 340X149, 340X151, 340X161, 340X163, 340X165, 340X173, 340X175, 340X177, 340X181, 340X182, 340X183, 340X185, 340X186, 340X187, 340X188, 340X189, 340X190, 340X192, 340X193, 340X194, 340X195, 340X196, 340X197, 340X198, tool (#1), 344X1, 344X2, 344X4, 344X5, 344X6, 344X7, 344X9, 344X10, 344X12, 344X13, 344X14, 344X15, 344X16, 344X18, 344X19, 344X20, 344X22, 344X23, 344X24, 344X25, 344X27, 344X28, 344X30, 344X31, 344X33, 344X34, 344X36, 344X37, 344X39, 344X40, 344X42, 344X43, 344X45, 344X46, 344X48, 344X49, 344X54, 344X55, 344X57, 344X58, 344X60, 344X61, 344X63, 344X64, 344X66, 344X67, 344X69, 344X70, 344X75, 344X76, 344X78, 344X81, 344X85, 344X90, 344X91, 344X97, 344X99, 344X102, 344X103, 344X105, 344X106, 344X108, 344X109, 344X111, 344X114, 344X115, 344X117, 344X118, 344X120, 344X121, 344X123, 344X126, 344X127, 344X129, 344X130, 344X132, 344X133, 344X138, 344X139, 344X141, 344X142, 344X144, 344X145, 344X150, 344X151, 344X153, 344X154, 344X156, 344X157, 344X159, 344X162, 344X163, 344X165, 344X166, 344X168, 344X169, 344X171, 344X174, 344X175, 344X177, 344X178, 344X180, 344X181, 344X198, 344X199, 344X201, 344X202, 344X204, 344X205, 344X210, 344X212, 344X213, 344X214, 344X215, 344X216, 344X218, 344X219, 344X221, 344X222, 344X224, 344X225, 344X231, 344X233, 344X234, 344X236, 344X237, 344X239, 344X240, 344X242, 344X243, 344X245, 344X246, 344X249, 344X251, 344X252, 344X258, 344X260, 344X261, 344X263, 344X264, 344X266, 344X267, 344X270, 344X273, 344X278, 344X279, 344X281, 344X282, 344X284, 344X285, 344X287, 344X288, 344X290, 344X291, 344X293, 344X294, 344X296, 344X297, 344X299, 344X300, 344X302, 344X303, 344X306, 344X309, 344X314, 344X317, 344X318, 344X320, 344X321, 344X323, 344X324, 344X335, 344X336, 344X338, 344X339, 344X341, 344X342, 344X347, 344X348, 344X349, 344X350, 344X351, 344X352, 344X355, 344X356, 344X358, 344X359, 344X361, 344X362, 344X364, 344X365, 344X367, 344X368, 344X370, 344X371, 344X376, 344X377, 344X379, 344X380, 344X382, 344X383, 344X385, 344X386, 344X388, 344X389, 344X391, 344X392, 344X394, 344X395, TOOL, 360X1, 360X2, 360X5, 360X23, 360X24, 360X27, 360X34, 360X38, 360X45, 360X46, 360X49, 360X57, 360X60, 360X93, 360X103, 360X109, 360X111, 360X115, 360X116, 360X118, 360X124, 360X131, 360X132, 360X140, 360X148, 360X155, 360X156, 360X164, 360X175, 360X185, 360X186, 360X197, 360X210, 360X218, 360X228, 360X229, 360X240, 360X251, 360X261, 360X262, 360X273, 360X284, 360X294, 360X295, 360X306, 360X317, 360X327, 360X328, 360X335, 360X336, 360X347, 360X358, 360X368, 360X369, 360X380, 360X391, 360X401, 360X402, 360X413, 360X424, 360X434, 360X435, 360X446, 360X454, 360X465, 360X475, 360X476, 360X487, 360X498, 360X508, 360X509, 360X520, 360X531, 360X541, 360X542, 360X553, 360X564, 360X572, 360X582, 360X583, 360X594, 360X604, 360X611, 360X612, 360X620, 360X628, 360X635, 360X636, 360X644, 360X652, 360X659, 360X660, 360X668, 360X676, 360X697, 360X702, 360X705, 360X712, 360X713, 360X717, 360X741, 360X742, 360X745, 360X763, 360X764, 360X775, 360X778, 360X785, 360X789, 360X971, 360X986, 360X988, 360X996, 360X1002, 360X1005, 360X1008, 360X1019, 360X1030, 360X1041, 360X1049, 360X1052, 360X1071, 360X1074, 360X1096, 360X1115, 360X1129, 360X1137, 360X1139, 360X1189, 360X1192, 360X1203, 360X1225, 360X1247, 360X1288, 360X1296, 360X1298, 360X1306, 360X1312, 360X1314, 360X1330, 360X1357, 360X1384, 400X4, 400X5, 400X12, 400X13, 400X14, 400X15, 400X16, 400X19, 400X20, 400X21, 400X22, 400X23, 400X24, 400X28, 400X30, 400X31, 400X32, 400X33, 400X34, 400X35, 400X36, 400X37, 400X38, 400X40, 400X56, 400X57, 400X58, 400X59, 400X66, 400X67, 400X68, 400X69, 400X70, 400X71, 400X72, 400X73, 400X74, 400X75, 400X76, 400X77, 400X78, 400X79, 400X80, 400X81, 400X85, 400X86, 400X87, 400X88, 400X89, 400X90, 400X91, 400X92, 400X93, 400X94, 400X95, 400X96, 400X97, 400X98, 400X99, 400X100, 400X108, 400X109, 400X110, 400X111, 400X112, 400X114, 400X115, 400X116, 400X117, 400X118, 400X119, 400X120, 400X121, 400X122, 400X123, 400X124, 400X125, 400X132, 400X133, 400X134, 400X135, 400X136, 400X138, 400X139, 400X140, 400X141, 400X142, 400X144, 400X145, 400X146, 400X147, 400X148, 400X149, 400X150, 400X151, 400X153, 400X154, 400X156, 400X157, 400X158, 400X159, 400X160, 400X170, 400X183, 400X187, 400X188, 400X189, 400X192, 400X193, 400X194, 400X195, 400X196, 400X197, 400X198, 400X199, 400X200, 400X201, 400X202, 400X204, 400X205, 400X208, 400X209, 400X210, 400X211, 400X212, 400X213, 400X214, 400X215, 400X216, 400X217, 400X226, 400X228, 420X1, 420X4, 420X8, 420X12, 420X13, 420X14, 420X15, 420X16, 420X19, 420X20, 420X21, 420X22, 420X23, 420X28, 420X30, 420X31, 420X32, 420X33, 420X34, 420X35, 420X36, 420X37, 420X38, 420X39, 420X40, 420X48, 420X50, 420X66, 420X67, 420X68, 420X69, 420X70, 420X71, 420X72, 420X73, 420X74, 420X75, 420X76, 420X77, 420X78, 420X79, 420X80, 420X81, 420X85, 420X86, 420X87, 420X88, 420X89, 420X90, 420X91, 420X92, 420X93, 420X94, 420X95, 420X96, 420X97, 420X98, 420X99, 420X100, 420X103, 420X108, 420X110, 420X112, 420X114, 420X115, 420X116, 420X117, 420X118, 420X120, 420X121, 420X122, 420X123, 420X124, 420X132, 420X134, 420X135, 420X136, 420X138, 420X139, 420X140, 420X141, 420X142, 420X143, 420X144, 420X145, 420X146, 420X147, 420X148, 420X150, 420X151, 420X152, 420X153, 420X154, 420X156, 420X157, 420X159, 420X160, 420X164, 420X187, 420X188, 420X189, 420X192, 420X193, 420X194, 420X195, 420X196, 420X197, 420X198, 420X199, 420X200, 420X201, 420X202, 420X205, 420X208, 420X209, 420X210, 420X211, 420X212, 420X213, 420X214, 420X215, 420X216, 420X217, 420X228, TOOL (#1), 440AX1, 440AX2, 440AX4, 440AX5, 440AX6, 440AX7, 440AX8, 440AX9, 440AX10, 440AX11, 440AX12, 440AX13, 440AX14, 440AX15, 440AX16, 440AX17, 440AX18, 440AX19, 440AX20, 440AX21, 440AX22, 440AX23, 440AX24, 440AX25, 440AX26, 440AX27, 440AX28, 440AX29, 440AX30, 440AX31, 440AX32, 440AX33, 440AX34, 440AX35, 440AX36, 440AX37, 440AX38, 440AX39, 440AX40, 440AX41, 440AX42, 440AX43, 440AX44, 440AX45, 440AX46, 440AX47, 440AX48, 440AX49, 440AX50, 440AX51, 440AX55, 440AX56, 440AX57, 440AX58, 440AX59, 440AX60, 440AX61, 440AX62, 440AX63, 440AX64, 440AX65, 440AX66, 440AX67, 440AX68, 440AX69, 440AX70, 440AX71, 440AX72, 440AX73, 440AX74, 440AX75, 440AX76, 440AX77, 440AX78, 440AX79, 440AX80, 440AX81, 440AX82, 440AX83, 440AX84, 440AX85, 440AX86, 440AX87, 440AX88, 440AX89, 440AX90, 440AX91, 440AX92, 440AX93, 440AX94, 440AX95, 440AX96, 440AX97, 440AX98, 440AX99, 440AX100, 440AX101, 440AX102, 440AX106, 440AX107, 440AX108, 440AX109, 440AX110, 440AX111, 440AX112, 440AX113, 440AX114, 440AX115, 440AX116, 440AX117, 440AX118, 440AX119, 440AX120, 440AX121, 440AX122, 440AX123, 440AX124, 440AX125, 440AX126, 440AX127, 440AX128, 440AX129, 440AX130, 440AX131, 440AX132, 440AX133, 440AX134, 440AX135, 440AX136, 440AX137, 440AX138, 440AX139, 440AX140, 440AX141, 440AX142, 440AX143, 440AX144, 440AX145, 440AX146, 440AX147, 440AX148, 440AX149, 440AX150, 440AX151, 440AX152, 440AX153, 440AX154, 440AX158, 440AX159, 440AX160, 440AX161, 440AX162, 440AX163, 440AX164, 440AX165, 440AX166, 440AX167, 440AX168, 440AX169, 440AX170, 440AX171, 440AX172, 440AX173, 440AX174, 440AX175, 440AX176, 440AX177, 440AX178, 440AX179, 440AX180, 440AX181, 440AX182, 440AX183, 440AX184, 440AX185, 440AX186, 440AX187, 440AX188, 440AX189, 440AX190, 440AX191, 440AX192, 440AX193, 440AX194, 440AX195, 440AX196, 440AX197, 440AX198, 440AX199, 440AX200, 440AX201, 440AX202, 440AX203, 440AX204, 440AX205, 440AX206, 440AX207, 440AX210, 440AX211, 440AX212, Tool (#3), 520X1, 520X3, 520X4, 520X6, 520X7, 520X8, 520X11, 520X12, 520X13, 520X16, 520X17, 520X18, 520X19, 520X21, 520X22, 520X23, 520X24, 520X26, 520X27, 520X28, 520X29, 520X31, 520X32, 520X33, 520X34, 520X36, 520X37, 520X38, 520X39, 520X41, 520X42, 520X43, 520X44, 520X46, 520X47, 520X48, 520X49, 520X51, 520X52, 520X53, 520X54, 520X56, 520X57, 520X58, 520X59, 520X61, 520X62, 520X63, 520X64, 520X66, 520X67, 520X68, 520X69, 520X71, 520X72, 520X73, 520X74, 520X76, 520X77, 520X78, 520X79, 520X81, 520X82, 520X83, 520X84, 520X86, 520X87, 520X88, 520X89, 520X91, 520X92, 520X93, 520X94, 520X96, 520X97, 520X98, 520X99, 520X101, 520X102, 520X103, 520X104, 520X106, 520X107, 520X108, 520X109, 520X111, 520X112, 520X113, 520X117, 520X118, 520X119, 520X123, 520X124, 520X128, 520X129, 520X130, 520X134, 520X135, 520X137, 520X140, 520X143, 520X144, 520X158, 520X159, 520X160, 520X161, 520X162, 520X165, 520X166, 520X167, 520X168, 520X169, 520X174, 520X176, 520X177, 520X178, 520X179, 520X180, 520X181, 520X182, 520X183, 520X184, 520X185, 520X186, 520X230, 520X231, 520X232, 520X233, 520X234, 520X235, 520X236, 520X237, 520X238, 520X239, 520X240, 520X241, 520X242, 520X243, 520X244, 520X245, 520X246, 520X252, 520X253, 520X254, 520X255, 520X256, 520X257, 520X258, 520X259, 520X260, 520X261, 520X262, 520X263, 520X264, 520X265, 520X266, 520X267, 520X281, 520X282, 520X283, 520X284, 520X285, 520X287, 520X288, 520X289, 520X290, 520X291, 520X293, 520X294, 520X295, 520X296, 520X297, 520X298, 520X305, 520X306, 520X307, 520X308, 520X309, 520X311, 520X312, 520X313, 520X314, 520X315, 520X317, 520X318, 520X319, 520X320, 520X321, 520X322, 520X323, 520X324, 520X325, 520X326, 520X327, 520X329, 520X330, 520X332, 520X333, 520X345, 520X351, 520X353, 520X375, 520X376, 520X377, 520X380, 520X381, 520X387, 520X388, 520X389, 520X390, 520X391, 520X392, 520X393, 520X394, 520X395, 520X396, 520X397, 520X399, 520X400, 520X403, 520X404, 520X405, 520X406, 520X407, 520X408, 520X409, 520X410, 520X411, 520X412, 520X429, 520X432, TOOL (#2), 750X1, 750X2, 750X23, 750X24, 750X27, 750X34, 750X45, 750X46, 750X49, 750X57, 750X60, 750X90, 750X103, 750X109, 750X111, 750X115, 750X116, 750X118, 750X124, 750X131, 750X132, 750X140, 750X148, 750X155, 750X156, 750X164, 750X175, 750X185, 750X186, 750X197, 750X210, 750X218, 750X228, 750X229, 750X240, 750X251, 750X261, 750X262, 750X273, 750X284, 750X294, 750X295, 750X306, 750X317, 750X327, 750X328, 750X335, 750X336, 750X347, 750X358, 750X368, 750X369, 750X380, 750X391, 750X401, 750X402, 750X413, 750X424, 750X434, 750X435, 750X446, 750X454, 750X465, 750X475, 750X476, 750X487, 750X498, 750X508, 750X509, 750X520, 750X531, 750X541, 750X542, 750X553, 750X564, 750X572, 750X582, 750X583, 750X594, 750X604, 750X611, 750X612, 750X620, 750X628, 750X635, 750X636, 750X644, 750X652, 750X659, 750X660, 750X668, 750X676, 750X697, 750X702, 750X705, 750X713, 750X717, 750X741, 750X742, 750X745, 750X763, 750X764, 750X775, 750X778, 750X785, 750X789, 750X971, 750X986, 750X988, 750X996, 750X1002, 750X1005, 750X1008, 750X1019, 750X1030, 750X1041, 750X1049, 750X1052, 750X1071, 750X1074, 750X1096, 750X1115, 750X1129, 750X1137, 750X1139, 750X1164, 750X1189, 750X1192, 750X1203, 750X1225, 750X1247, 750X1288, 750X1296, 750X1298, 750X1306, 750X1312, 750X1314, 750X1330, 750X1357, 750X1384",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-f3cfef4e8b09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_new_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_xgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxgb_new_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxgb_new_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxgb_new_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_new_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost-0.6-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    263\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[1;32m    264\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                                                                 feature_types)\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_pandas_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost-0.6-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[0;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    182\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[1;32m    183\u001b[0m Did not expect the data types in fields \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in fields TOOL_ID, 210X1, 210X2, 210X3, 210X4, 210X5, 210X6, 210X7, 210X8, 210X9, 210X10, 210X11, 210X12, 210X13, 210X14, 210X15, 210X16, 210X17, 210X18, 210X19, 210X20, 210X21, 210X23, 210X25, 210X26, 210X27, 210X28, 210X29, 210X30, 210X31, 210X32, 210X33, 210X34, 210X35, 210X36, 210X37, 210X38, 210X39, 210X40, 210X41, 210X42, 210X43, 210X44, 210X45, 210X46, 210X47, 210X48, 210X49, 210X50, 210X51, 210X52, 210X53, 210X54, 210X55, 210X56, 210X57, 210X58, 210X59, 210X60, 210X61, 210X62, 210X63, 210X64, 210X65, 210X66, 210X67, 210X68, 210X69, 210X70, 210X71, 210X72, 210X73, 210X74, 210X75, 210X76, 210X77, 210X80, 210X81, 210X82, 210X83, 210X84, 210X85, 210X86, 210X87, 210X88, 210X89, 210X90, 210X91, 210X92, 210X93, 210X94, 210X95, 210X96, 210X97, 210X98, 210X99, 210X100, 210X101, 210X102, 210X104, 210X105, 210X106, 210X107, 210X108, 210X109, 210X110, 210X111, 210X112, 210X113, 210X114, 210X115, 210X116, 210X117, 210X118, 210X119, 210X120, 210X121, 210X122, 210X123, 210X124, 210X125, 210X127, 210X128, 210X129, 210X130, 210X131, 210X132, 210X133, 210X134, 210X135, 210X136, 210X137, 210X138, 210X139, 210X140, 210X141, 210X142, 210X143, 210X144, 210X145, 210X146, 210X147, 210X148, 210X149, 210X150, 210X151, 210X152, 210X153, 210X154, 210X155, 210X156, 210X157, 210X158, 210X159, 210X160, 210X161, 210X162, 210X163, 210X164, 210X165, 210X166, 210X167, 210X168, 210X169, 210X170, 210X171, 210X172, 210X173, 210X174, 210X175, 210X176, 210X177, 210X178, 210X179, 210X180, 210X181, 210X182, 210X183, 210X184, 210X185, 210X186, 210X187, 210X188, 210X189, 210X190, 210X191, 210X192, 210X193, 210X194, 210X195, 210X199, 210X200, 210X201, 210X202, 210X203, 210X206, 210X207, 210X209, 210X210, 210X211, 210X212, 210X214, 210X216, 210X217, 210X218, 210X219, 210X220, 210X221, 210X222, 210X225, 210X226, 210X228, 210X229, 210X230, 210X231, Tool, 220X2, 220X3, 220X4, 220X5, 220X6, 220X7, 220X8, 220X9, 220X10, 220X11, 220X12, 220X13, 220X14, 220X15, 220X18, 220X19, 220X20, 220X21, 220X26, 220X27, 220X28, 220X29, 220X30, 220X31, 220X32, 220X33, 220X53, 220X54, 220X55, 220X58, 220X66, 220X99, 220X107, 220X108, 220X110, 220X112, 220X114, 220X116, 220X118, 220X120, 220X122, 220X124, 220X126, 220X128, 220X130, 220X132, 220X141, 220X142, 220X143, 220X153, 220X155, 220X156, 220X157, 220X159, 220X163, 220X164, 220X165, 220X166, 220X167, 220X168, 220X169, 220X170, 220X171, 220X172, 220X173, 220X174, 220X175, 220X176, 220X177, 220X178, 220X179, 220X180, 220X181, 220X182, 220X183, 220X184, 220X185, 220X186, 220X187, 220X188, 220X189, 220X190, 220X191, 220X192, 220X193, 220X194, 220X195, 220X196, 220X197, 220X198, 220X200, 220X201, 220X204, 220X216, 220X217, 220X218, 220X223, 220X224, 220X237, 220X241, 220X242, 220X247, 220X248, 220X249, 220X260, 220X262, 220X266, 220X269, 220X270, 220X271, 220X272, 220X273, 220X274, 220X275, 220X277, 220X279, 220X281, 220X282, 220X284, 220X286, 220X288, 220X289, 220X290, 220X291, 220X293, 220X294, 220X295, 220X296, 220X297, 220X298, 220X299, 220X300, 220X301, 220X302, 220X303, 220X304, 220X305, 220X306, 220X307, 220X308, 220X309, 220X310, 220X311, 220X312, 220X313, 220X314, 220X315, 220X316, 220X317, 220X318, 220X321, 220X322, 220X323, 220X324, 220X325, 220X326, 220X327, 220X328, 220X329, 220X330, 220X331, 220X332, 220X333, 220X334, 220X335, 220X336, 220X337, 220X338, 220X339, 220X340, 220X341, 220X342, 220X343, 220X344, 220X345, 220X346, 220X347, 220X348, 220X349, 220X350, 220X351, 220X352, 220X353, 220X354, 220X355, 220X356, 220X357, 220X358, 220X359, 220X360, 220X361, 220X362, 220X363, 220X364, 220X365, 220X366, 220X367, 220X368, 220X369, 220X370, 220X371, 220X372, 220X373, 220X374, 220X375, 220X376, 220X377, 220X378, 220X379, 220X380, 220X381, 220X382, 220X383, 220X384, 220X385, 220X386, 220X387, 220X388, 220X389, 220X390, 220X392, 220X393, 220X394, 220X395, 220X396, 220X397, 220X398, 220X399, 220X400, 220X402, 220X403, 220X404, 220X405, 220X406, 220X407, 220X408, 220X409, 220X410, 220X411, 220X412, 220X413, 220X414, 220X415, 220X416, 220X417, 220X419, 220X420, 220X421, 220X422, 220X423, 220X424, 220X425, 220X427, 220X428, 220X429, 220X430, 220X431, 220X433, 220X434, 220X435, 220X437, 220X438, 220X439, 220X440, 220X441, 220X442, 220X443, 220X444, 220X445, 220X446, 220X447, 220X448, 220X449, 220X450, 220X451, 220X452, 220X454, 220X456, 220X457, 220X458, 220X459, 220X461, 220X462, 220X463, 220X465, 220X467, 220X468, 220X469, 220X470, 220X471, 220X472, 220X474, 220X475, 220X476, 220X477, 220X478, 220X479, 220X480, 220X481, 220X482, 220X483, 220X484, 220X485, 220X486, 220X487, 220X488, 220X489, 220X490, 220X491, 220X492, 220X493, 220X494, 220X495, 220X496, 220X497, 220X498, 220X499, 220X500, 220X501, 220X502, 220X503, 220X504, 220X505, 220X506, 220X507, 220X508, 220X509, 220X510, 220X512, 220X514, 220X515, 220X516, 220X517, 220X518, 220X520, 220X521, 220X522, 220X523, 220X524, 220X526, 220X528, 220X529, 220X530, 220X531, 220X532, 220X533, 220X535, 220X539, 220X540, 220X541, 220X549, 220X550, 220X551, 220X554, 220X557, 220X570, 220X571, TOOL_ID (#1), 300X1, 300X5, 300X8, 300X11, 300X12, 300X15, 300X16, 300X17, 300X21, TOOL_ID (#2), 310X2, 310X3, 310X4, 310X5, 310X6, 310X8, 310X9, 310X10, 310X11, 310X12, 310X13, 310X14, 310X15, 310X19, 310X20, 310X21, 310X22, 310X23, 310X24, 310X27, 310X28, 310X29, 310X30, 310X31, 310X32, 310X33, 310X34, 310X36, 310X37, 310X38, 310X42, 310X43, 310X44, 310X88, 310X96, 310X97, 310X99, 310X101, 310X103, 310X105, 310X107, 310X109, 310X111, 310X113, 310X115, 310X117, 310X119, 310X121, 310X130, 310X131, 310X132, 310X147, 310X148, 310X149, 310X150, 310X151, 310X152, 310X153, 310X154, 310X155, 310X156, 310X157, 310X158, 310X159, 310X160, 310X161, 310X162, 310X163, 310X164, 310X165, 310X166, 310X167, 310X168, 310X169, 310X170, 310X171, 310X172, 310X173, 310X174, 310X175, 310X176, 310X177, 310X178, 310X179, 310X180, 310X181, 310X188, 310X200, 310X201, 310X202, 310X206, 310X207, TOOL_ID (#3), 311X1, 311X4, 311X7, 311X8, 311X9, 311X10, 311X11, 311X12, 311X15, 311X16, 311X17, 311X18, 311X19, 311X20, 311X21, 311X22, 311X23, 311X27, 311X28, 311X33, 311X39, 311X41, 311X42, 311X43, 311X44, 311X45, 311X47, 311X48, 311X50, 311X55, 311X56, 311X57, 311X58, 311X59, 311X60, 311X61, 311X62, 311X63, 311X64, 311X66, 311X67, 311X68, 311X69, 311X70, 311X71, 311X72, 311X73, 311X74, 311X75, 311X76, 311X77, 311X79, 311X80, 311X82, 311X83, 311X85, 311X86, 311X87, 311X90, 311X91, 311X94, 311X95, 311X96, 311X97, 311X98, 311X101, 311X102, 311X103, 311X104, 311X105, 311X106, 311X107, 311X108, 311X109, 311X110, 311X111, 311X112, 311X113, 311X114, 311X115, 311X116, 311X117, 311X118, 311X130, 311X154, 311X155, 311X156, 311X157, 311X158, 311X159, 311X160, 311X161, 311X162, 311X164, 311X165, 311X168, 311X170, 311X171, 311X173, 311X174, 311X175, 311X178, 311X179, 311X182, 311X183, 311X184, 311X185, 311X191, 311X192, 311X193, 311X195, 311X196, 311X197, 311X199, 311X200, 311X201, 311X202, 311X203, 311X204, 311X206, 311X217, 311X218, 311X219, 311X220, 311X221, 311X222, 311X223, 311X224, 311X225, 261X226, 261X227, 261X228, 261X229, 261X230, 261X231, 261X232, 261X233, 261X234, 261X235, 261X236, 261X237, 261X238, 261X239, 261X240, 261X241, 261X242, 261X244, 261X245, 261X246, 261X247, 261X248, 261X249, 261X250, 261X251, 261X252, 261X254, 261X255, 261X256, 261X257, 261X258, 261X259, 261X260, 261X261, 261X262, 261X264, 261X265, 261X266, 261X267, 261X268, 261X269, 261X270, 261X271, 261X272, 261X274, 261X275, 261X276, 261X277, 261X278, 261X279, 261X280, 261X281, 261X282, 261X284, 261X285, 261X286, 261X287, 261X288, 261X289, 261X290, 261X291, 261X292, 261X294, 261X295, 261X296, 261X310, 261X315, 261X318, 261X319, 261X321, 261X322, 261X323, 261X324, 261X325, 261X326, 261X328, 261X331, 261X332, 261X333, 261X334, 261X335, 261X336, 261X337, 261X338, 261X340, 261X341, 261X342, 261X343, 261X344, 261X345, 261X346, 261X347, 261X348, 261X351, 261X354, 261X356, 261X357, 261X359, 261X360, 261X361, 261X364, 261X365, 261X368, 261X369, 261X370, 261X371, 261X377, 261X378, 261X379, 261X381, 261X382, 261X383, 261X385, 261X386, 261X387, 261X388, 261X389, 261X390, 261X403, 261X404, 261X405, 261X406, 261X407, 261X408, 261X410, 261X411, 261X412, 261X413, 261X414, 261X415, 261X416, 261X417, 261X418, 261X420, 261X421, 261X422, 261X423, 261X424, 261X425, 261X426, 261X427, 261X428, 261X430, 261X431, 261X432, 261X433, 261X434, 261X435, 261X436, 261X437, 261X438, 261X440, 261X441, 261X442, 261X443, 261X444, 261X445, 261X446, 261X447, 261X448, 261X450, 261X451, 261X452, 261X453, 261X454, 261X455, 261X456, 261X457, 261X458, 261X460, 261X461, 261X462, 261X463, 261X464, 261X465, 261X466, 261X467, 261X468, 261X470, 261X471, 261X472, 261X473, 261X474, 261X475, 261X476, 261X477, 261X478, 261X480, 261X481, 261X482, 261X501, 261X512, 261X513, 261X517, 261X518, 261X519, 261X520, 261X521, 261X522, 261X523, 261X524, 261X526, 261X527, 261X528, 261X529, 261X530, 261X531, 261X532, 261X533, 261X534, 261X536, 261X537, 261X540, 261X542, 261X543, 261X545, 261X546, 261X547, 261X550, 261X551, 261X554, 261X555, 261X556, 261X557, 261X563, 261X564, 261X565, 261X567, 261X568, 261X569, 261X571, 261X572, 261X573, 261X574, 261X575, 261X576, 261X589, 261X590, 261X591, 261X592, 261X593, 261X594, 261X596, 261X597, 261X598, 261X599, 261X600, 261X601, 261X602, 261X603, 261X604, 261X606, 261X607, 261X608, 261X609, 261X610, 261X611, 261X612, 261X613, 261X614, 261X616, 261X617, 261X618, 261X619, 261X620, 261X621, 261X622, 261X623, 261X624, 261X626, 261X627, 261X628, 261X629, 261X630, 261X631, 261X632, 261X633, 261X634, 261X636, 261X637, 261X638, 261X639, 261X640, 261X641, 261X642, 261X643, 261X644, 261X646, 261X647, 261X648, 261X649, 261X650, 261X651, 261X652, 261X653, 261X654, 261X656, 261X657, 261X658, 261X659, 261X660, 261X661, 261X662, 261X663, 261X664, 261X666, 261X667, 261X668, 261X687, 261X688, 261X689, 261X693, 261X694, 261X695, 261X696, 261X701, 261X703, 261X704, 261X705, 261X706, 261X707, 261X708, 261X709, 261X710, 261X712, 261X713, 261X714, 261X715, 261X716, 261X717, 261X718, 261X719, 261X720, 261X723, 261X726, 261X728, 261X729, 261X731, 261X732, 261X733, 261X736, 261X737, 261X740, 261X741, 261X742, 261X743, 261X749, 261X750, 261X751, 261X753, 261X754, 261X755, 261X757, 261X758, 261X759, 261X760, 261X761, 261X762, Tool (#1), 312X1, 312X2, 312X3, 312X4, 312X6, 312X7, 312X8, 312X11, 312X12, 312X13, 312X16, 312X17, 312X18, 312X21, 312X22, 312X23, 312X26, 312X27, 312X28, 312X31, 312X32, 312X33, 312X36, 312X37, 312X38, 312X41, 312X42, 312X43, 312X46, 312X47, 312X48, 312X51, 312X52, 312X53, 312X54, 312X55, 312X57, 312X58, 312X59, 312X60, 312X61, 312X63, 312X64, 312X65, 312X66, 312X67, 312X69, 312X70, 312X71, 312X72, 312X73, 312X75, 312X76, 312X77, 312X78, 312X79, 312X81, 312X82, 312X83, 312X84, 312X85, 312X87, 312X88, 312X89, 312X90, 312X91, 312X93, 312X94, 312X95, 312X96, 312X97, 312X99, 312X100, 312X101, 312X102, 312X105, 312X111, 312X112, 312X113, 312X114, 312X115, 312X117, 312X118, 312X119, 312X120, 312X121, 312X123, 312X124, 312X125, 312X126, 312X127, 312X129, 312X130, 312X131, 312X132, 312X133, 312X135, 312X136, 312X137, 312X138, 312X139, 312X141, 312X142, 312X143, 312X144, 312X145, 312X147, 312X153, 312X154, 312X155, 312X159, 312X160, 312X161, 312X162, 312X163, 312X165, 312X166, 312X167, 312X168, 312X169, 312X171, 312X173, 312X174, 312X175, 312X177, 312X180, 312X181, 312X183, 312X185, 312X186, 312X187, 312X189, 312X191, 312X192, 312X193, 312X197, 312X198, 312X199, 312X203, 312X207, 312X208, 312X209, 312X210, 312X211, 312X213, 312X214, 312X215, 312X216, 312X217, 312X219, 312X220, 312X221, 312X222, 312X223, 312X225, 312X227, 312X228, 312X229, 312X231, 312X233, 312X234, 312X235, 312X236, 312X238, 312X239, 312X240, 312X242, 312X244, 312X245, 312X246, 312X249, 312X250, 312X251, 312X253, 312X254, 312X255, 312X256, 312X257, 312X259, 312X260, 312X261, 312X262, 312X263, 312X265, 312X266, 312X267, 312X268, 312X269, 312X272, 312X277, 312X278, 312X279, 312X280, 312X281, 312X283, 312X284, 312X285, 312X286, 312X287, 312X289, 312X290, 312X291, 312X292, 312X293, 312X295, 312X296, 312X297, 312X298, 312X299, 312X303, 312X307, 312X308, 312X309, 312X310, 312X311, 312X313, 312X315, 312X327, 312X331, 312X332, 312X333, 312X334, 312X335, 312X337, 312X338, 312X339, 312X340, 312X341, 312X345, 312X349, 312X350, 312X351, 312X352, 312X353, 312X355, 312X356, 312X357, 312X358, 312X359, 312X361, 312X362, 312X363, 312X364, 312X365, 312X367, 312X373, 312X374, 312X375, 312X376, 312X377, 312X379, 312X380, 312X381, 312X382, 312X383, 312X385, 312X386, 312X387, 312X388, 312X389, 312X421, 312X423, 312X424, 312X425, 312X426, 312X427, 312X428, 312X429, 312X430, 312X435, 312X436, 312X438, 312X439, 312X440, 312X441, 312X442, 312X444, 312X445, 312X446, 312X447, 312X448, 312X456, 312X457, 312X458, 312X459, 312X462, 312X463, 312X464, 312X465, 312X468, 312X469, 312X470, 312X471, 312X474, 312X475, 312X476, 312X477, 312X478, 312X480, 312X481, 312X482, 312X483, 312X486, 312X487, 312X488, 312X489, 312X510, 312X511, 312X516, 312X517, 312X518, 312X519, 312X520, 312X522, 312X523, 312X524, 312X525, 312X528, 312X529, 312X530, 312X531, 312X552, 312X553, 312X554, 312X555, 312X558, 312X559, 312X560, 312X561, 312X564, 312X565, 312X566, 312X567, 312X570, 312X574, 312X576, 312X577, 312X578, 312X579, 312X580, 312X582, 312X583, 312X584, 312X585, 312X586, 312X588, 312X589, 312X590, 312X591, 312X592, 312X594, 312X595, 312X596, 312X597, 312X598, 312X600, 312X601, 312X603, 312X630, 312X631, 312X632, 312X633, 312X634, 312X636, 312X637, 312X638, 312X639, 312X640, 312X642, 312X643, 312X644, 312X645, 312X666, 312X667, 312X668, 312X669, 312X670, 312X672, 312X673, 312X674, 312X675, 312X676, 312X678, 312X679, 312X680, 312X681, 312X682, 312X687, 312X688, 312X690, 312X691, 312X692, 312X693, 312X694, 312X695, 312X696, 312X697, 312X698, 312X699, 312X700, 312X701, 312X702, 312X703, 312X704, 312X710, 312X711, 312X712, 312X713, 312X714, 312X716, 312X717, 312X718, 312X719, 312X720, 312X722, 312X723, 312X724, 312X725, 312X726, 312X728, 312X729, 312X730, 312X731, 312X732, 312X734, 312X735, 312X736, 312X737, 312X738, 312X740, 312X741, 312X742, 312X743, 312X744, 312X746, 312X752, 312X753, 312X754, 312X755, 312X758, 312X759, 312X760, 312X761, 312X762, 312X764, 312X765, 312X766, 312X767, 312X768, 312X770, 312X771, 312X772, 312X773, 312X774, 312X776, 312X777, 312X778, 312X779, 312X780, 312X782, 312X783, 312X784, 312X785, 312X786, 312X788, 312X789, 312X790, 312X791, 312X792, Tool (#2), 330X1, 330X2, 330X3, 330X5, 330X8, 330X9, 330X11, 330X12, 330X21, 330X22, 330X23, 330X25, 330X28, 330X29, 330X31, 330X35, 330X38, 330X41, 330X42, 330X43, 330X45, 330X48, 330X49, 330X51, 330X52, 330X53, 330X55, 330X58, 330X59, 330X61, 330X62, 330X71, 330X72, 330X81, 330X85, 330X88, 330X94, 330X97, 330X98, 330X100, 330X101, 330X102, 330X103, 330X104, 330X105, 330X106, 330X107, 330X108, 330X110, 330X111, 330X112, 330X113, 330X114, 330X118, 330X119, 330X120, 330X121, 330X125, 330X126, 330X127, 330X128, 330X132, 330X133, 330X134, 330X135, 330X139, 330X140, 330X141, 330X142, 330X146, 330X147, 330X148, 330X149, 330X155, 330X157, 330X158, 330X159, 330X165, 330X167, 330X168, 330X169, 330X175, 330X177, 330X178, 330X179, 330X185, 330X188, 330X189, 330X190, 330X191, 330X195, 330X196, 330X197, 330X198, 330X204, 330X206, 330X207, 330X208, 330X214, 330X216, 330X217, 330X218, 330X224, 330X226, 330X227, 330X228, 330X234, 330X236, 330X237, 330X238, 330X244, 330X246, 330X247, 330X248, 330X254, 330X256, 330X257, 330X258, 330X264, 330X266, 330X267, 330X268, 330X274, 330X276, 330X277, 330X278, 330X284, 330X286, 330X287, 330X288, 330X294, 330X296, 330X297, 330X298, 330X302, 330X303, 330X304, 330X305, 330X311, 330X313, 330X314, 330X315, 330X321, 330X323, 330X324, 330X325, 330X331, 330X333, 330X334, 330X335, 330X341, 330X343, 330X344, 330X345, 330X351, 330X353, 330X354, 330X355, 330X361, 330X363, 330X364, 330X365, 330X371, 330X373, 330X374, 330X375, 330X381, 330X383, 330X384, 330X385, 330X391, 330X393, 330X394, 330X395, 330X401, 330X403, 330X404, 330X405, 330X409, 330X410, 330X411, 330X412, 330X418, 330X420, 330X421, 330X422, 330X428, 330X430, 330X431, 330X432, 330X438, 330X440, 330X441, 330X442, 330X448, 330X450, 330X451, 330X452, 330X458, 330X460, 330X461, 330X462, 330X468, 330X470, 330X471, 330X472, 330X478, 330X480, 330X481, 330X482, 330X488, 330X490, 330X491, 330X492, 330X498, 330X501, 330X502, 330X508, 330X510, 330X511, 330X512, 330X516, 330X518, 330X519, 330X525, 330X527, 330X528, 330X529, 330X535, 330X537, 330X538, 330X539, 330X544, 330X546, 330X547, 330X548, 330X552, 330X553, 330X554, 330X555, 330X559, 330X560, 330X561, 330X562, 330X566, 330X567, 330X568, 330X569, 330X573, 330X574, 330X575, 330X576, 330X580, 330X581, 330X582, 330X583, 330X587, 330X588, 330X589, 330X590, 330X594, 330X595, 330X596, 330X597, 330X601, 330X602, 330X603, 330X604, 330X608, 330X609, 330X610, 330X611, 330X615, 330X616, 330X617, 330X624, 330X626, 330X627, 330X629, 330X631, 330X633, 330X634, 330X636, 330X638, 330X641, 330X643, 330X647, 330X669, 330X670, 330X671, 330X673, 330X676, 330X677, 330X689, 330X690, 330X691, 330X696, 330X697, 330X699, 330X700, 330X701, 330X703, 330X706, 330X707, 330X709, 330X710, 330X713, 330X716, 330X717, 330X719, 330X749, 330X769, 330X770, 330X788, 330X789, 330X798, 330X799, 330X808, 330X809, 330X818, 330X878, 330X892, 330X893, 330X894, 330X896, 330X897, 330X899, 330X901, 330X903, 330X906, 330X909, 330X910, 330X912, 330X915, 330X916, 330X919, 330X922, 330X925, 330X929, 330X932, 330X935, 330X939, 330X942, 330X945, 330X949, 330X950, 330X952, 330X955, 330X956, 330X959, 330X969, 330X970, 330X972, 330X975, 330X976, 330X979, 330X989, 330X992, 330X995, 330X999, 330X1009, 330X1010, 330X1016, 330X1019, 330X1022, 330X1025, 330X1029, 330X1030, 330X1031, 330X1033, 330X1034, 330X1036, 330X1053, 330X1076, 330X1077, 330X1079, 330X1082, 330X1083, 330X1086, 330X1089, 330X1092, 330X1096, 330X1099, 330X1109, 330X1112, 330X1126, 330X1129, 330X1132, 330X1146, 330X1156, 330X1166, 330X1172, 330X1173, 330X1174, 330X1176, 330X1177, 330X1179, 330X1181, 330X1186, 330X1187, 330X1188, 330X1190, 330X1191, 330X1193, 330X1200, 330X1202, 330X1204, 330X1207, 330X1214, 330X1226, 330X1228, 330X1231, 330X1248, 330X1250, 330X1252, 330X1255, tool, 340X1, 340X2, 340X3, 340X4, 340X5, 340X6, 340X7, 340X8, 340X9, 340X10, 340X11, 340X13, 340X15, 340X17, 340X18, 340X19, 340X20, 340X21, 340X22, 340X24, 340X25, 340X26, 340X27, 340X28, 340X29, 340X31, 340X33, 340X34, 340X35, 340X36, 340X37, 340X38, 340X39, 340X41, 340X42, 340X43, 340X45, 340X46, 340X47, 340X48, 340X49, 340X51, 340X53, 340X57, 340X59, 340X61, 340X65, 340X67, 340X69, 340X71, 340X73, 340X75, 340X77, 340X79, 340X81, 340X83, 340X85, 340X97, 340X99, 340X101, 340X105, 340X107, 340X108, 340X109, 340X110, 340X113, 340X115, 340X119, 340X121, 340X123, 340X124, 340X125, 340X126, 340X132, 340X133, 340X134, 340X138, 340X139, 340X140, 340X141, 340X143, 340X145, 340X147, 340X149, 340X151, 340X161, 340X163, 340X165, 340X173, 340X175, 340X177, 340X181, 340X182, 340X183, 340X185, 340X186, 340X187, 340X188, 340X189, 340X190, 340X192, 340X193, 340X194, 340X195, 340X196, 340X197, 340X198, tool (#1), 344X1, 344X2, 344X4, 344X5, 344X6, 344X7, 344X9, 344X10, 344X12, 344X13, 344X14, 344X15, 344X16, 344X18, 344X19, 344X20, 344X22, 344X23, 344X24, 344X25, 344X27, 344X28, 344X30, 344X31, 344X33, 344X34, 344X36, 344X37, 344X39, 344X40, 344X42, 344X43, 344X45, 344X46, 344X48, 344X49, 344X54, 344X55, 344X57, 344X58, 344X60, 344X61, 344X63, 344X64, 344X66, 344X67, 344X69, 344X70, 344X75, 344X76, 344X78, 344X81, 344X85, 344X90, 344X91, 344X97, 344X99, 344X102, 344X103, 344X105, 344X106, 344X108, 344X109, 344X111, 344X114, 344X115, 344X117, 344X118, 344X120, 344X121, 344X123, 344X126, 344X127, 344X129, 344X130, 344X132, 344X133, 344X138, 344X139, 344X141, 344X142, 344X144, 344X145, 344X150, 344X151, 344X153, 344X154, 344X156, 344X157, 344X159, 344X162, 344X163, 344X165, 344X166, 344X168, 344X169, 344X171, 344X174, 344X175, 344X177, 344X178, 344X180, 344X181, 344X198, 344X199, 344X201, 344X202, 344X204, 344X205, 344X210, 344X212, 344X213, 344X214, 344X215, 344X216, 344X218, 344X219, 344X221, 344X222, 344X224, 344X225, 344X231, 344X233, 344X234, 344X236, 344X237, 344X239, 344X240, 344X242, 344X243, 344X245, 344X246, 344X249, 344X251, 344X252, 344X258, 344X260, 344X261, 344X263, 344X264, 344X266, 344X267, 344X270, 344X273, 344X278, 344X279, 344X281, 344X282, 344X284, 344X285, 344X287, 344X288, 344X290, 344X291, 344X293, 344X294, 344X296, 344X297, 344X299, 344X300, 344X302, 344X303, 344X306, 344X309, 344X314, 344X317, 344X318, 344X320, 344X321, 344X323, 344X324, 344X335, 344X336, 344X338, 344X339, 344X341, 344X342, 344X347, 344X348, 344X349, 344X350, 344X351, 344X352, 344X355, 344X356, 344X358, 344X359, 344X361, 344X362, 344X364, 344X365, 344X367, 344X368, 344X370, 344X371, 344X376, 344X377, 344X379, 344X380, 344X382, 344X383, 344X385, 344X386, 344X388, 344X389, 344X391, 344X392, 344X394, 344X395, TOOL, 360X1, 360X2, 360X5, 360X23, 360X24, 360X27, 360X34, 360X38, 360X45, 360X46, 360X49, 360X57, 360X60, 360X93, 360X103, 360X109, 360X111, 360X115, 360X116, 360X118, 360X124, 360X131, 360X132, 360X140, 360X148, 360X155, 360X156, 360X164, 360X175, 360X185, 360X186, 360X197, 360X210, 360X218, 360X228, 360X229, 360X240, 360X251, 360X261, 360X262, 360X273, 360X284, 360X294, 360X295, 360X306, 360X317, 360X327, 360X328, 360X335, 360X336, 360X347, 360X358, 360X368, 360X369, 360X380, 360X391, 360X401, 360X402, 360X413, 360X424, 360X434, 360X435, 360X446, 360X454, 360X465, 360X475, 360X476, 360X487, 360X498, 360X508, 360X509, 360X520, 360X531, 360X541, 360X542, 360X553, 360X564, 360X572, 360X582, 360X583, 360X594, 360X604, 360X611, 360X612, 360X620, 360X628, 360X635, 360X636, 360X644, 360X652, 360X659, 360X660, 360X668, 360X676, 360X697, 360X702, 360X705, 360X712, 360X713, 360X717, 360X741, 360X742, 360X745, 360X763, 360X764, 360X775, 360X778, 360X785, 360X789, 360X971, 360X986, 360X988, 360X996, 360X1002, 360X1005, 360X1008, 360X1019, 360X1030, 360X1041, 360X1049, 360X1052, 360X1071, 360X1074, 360X1096, 360X1115, 360X1129, 360X1137, 360X1139, 360X1189, 360X1192, 360X1203, 360X1225, 360X1247, 360X1288, 360X1296, 360X1298, 360X1306, 360X1312, 360X1314, 360X1330, 360X1357, 360X1384, 400X4, 400X5, 400X12, 400X13, 400X14, 400X15, 400X16, 400X19, 400X20, 400X21, 400X22, 400X23, 400X24, 400X28, 400X30, 400X31, 400X32, 400X33, 400X34, 400X35, 400X36, 400X37, 400X38, 400X40, 400X56, 400X57, 400X58, 400X59, 400X66, 400X67, 400X68, 400X69, 400X70, 400X71, 400X72, 400X73, 400X74, 400X75, 400X76, 400X77, 400X78, 400X79, 400X80, 400X81, 400X85, 400X86, 400X87, 400X88, 400X89, 400X90, 400X91, 400X92, 400X93, 400X94, 400X95, 400X96, 400X97, 400X98, 400X99, 400X100, 400X108, 400X109, 400X110, 400X111, 400X112, 400X114, 400X115, 400X116, 400X117, 400X118, 400X119, 400X120, 400X121, 400X122, 400X123, 400X124, 400X125, 400X132, 400X133, 400X134, 400X135, 400X136, 400X138, 400X139, 400X140, 400X141, 400X142, 400X144, 400X145, 400X146, 400X147, 400X148, 400X149, 400X150, 400X151, 400X153, 400X154, 400X156, 400X157, 400X158, 400X159, 400X160, 400X170, 400X183, 400X187, 400X188, 400X189, 400X192, 400X193, 400X194, 400X195, 400X196, 400X197, 400X198, 400X199, 400X200, 400X201, 400X202, 400X204, 400X205, 400X208, 400X209, 400X210, 400X211, 400X212, 400X213, 400X214, 400X215, 400X216, 400X217, 400X226, 400X228, 420X1, 420X4, 420X8, 420X12, 420X13, 420X14, 420X15, 420X16, 420X19, 420X20, 420X21, 420X22, 420X23, 420X28, 420X30, 420X31, 420X32, 420X33, 420X34, 420X35, 420X36, 420X37, 420X38, 420X39, 420X40, 420X48, 420X50, 420X66, 420X67, 420X68, 420X69, 420X70, 420X71, 420X72, 420X73, 420X74, 420X75, 420X76, 420X77, 420X78, 420X79, 420X80, 420X81, 420X85, 420X86, 420X87, 420X88, 420X89, 420X90, 420X91, 420X92, 420X93, 420X94, 420X95, 420X96, 420X97, 420X98, 420X99, 420X100, 420X103, 420X108, 420X110, 420X112, 420X114, 420X115, 420X116, 420X117, 420X118, 420X120, 420X121, 420X122, 420X123, 420X124, 420X132, 420X134, 420X135, 420X136, 420X138, 420X139, 420X140, 420X141, 420X142, 420X143, 420X144, 420X145, 420X146, 420X147, 420X148, 420X150, 420X151, 420X152, 420X153, 420X154, 420X156, 420X157, 420X159, 420X160, 420X164, 420X187, 420X188, 420X189, 420X192, 420X193, 420X194, 420X195, 420X196, 420X197, 420X198, 420X199, 420X200, 420X201, 420X202, 420X205, 420X208, 420X209, 420X210, 420X211, 420X212, 420X213, 420X214, 420X215, 420X216, 420X217, 420X228, TOOL (#1), 440AX1, 440AX2, 440AX4, 440AX5, 440AX6, 440AX7, 440AX8, 440AX9, 440AX10, 440AX11, 440AX12, 440AX13, 440AX14, 440AX15, 440AX16, 440AX17, 440AX18, 440AX19, 440AX20, 440AX21, 440AX22, 440AX23, 440AX24, 440AX25, 440AX26, 440AX27, 440AX28, 440AX29, 440AX30, 440AX31, 440AX32, 440AX33, 440AX34, 440AX35, 440AX36, 440AX37, 440AX38, 440AX39, 440AX40, 440AX41, 440AX42, 440AX43, 440AX44, 440AX45, 440AX46, 440AX47, 440AX48, 440AX49, 440AX50, 440AX51, 440AX55, 440AX56, 440AX57, 440AX58, 440AX59, 440AX60, 440AX61, 440AX62, 440AX63, 440AX64, 440AX65, 440AX66, 440AX67, 440AX68, 440AX69, 440AX70, 440AX71, 440AX72, 440AX73, 440AX74, 440AX75, 440AX76, 440AX77, 440AX78, 440AX79, 440AX80, 440AX81, 440AX82, 440AX83, 440AX84, 440AX85, 440AX86, 440AX87, 440AX88, 440AX89, 440AX90, 440AX91, 440AX92, 440AX93, 440AX94, 440AX95, 440AX96, 440AX97, 440AX98, 440AX99, 440AX100, 440AX101, 440AX102, 440AX106, 440AX107, 440AX108, 440AX109, 440AX110, 440AX111, 440AX112, 440AX113, 440AX114, 440AX115, 440AX116, 440AX117, 440AX118, 440AX119, 440AX120, 440AX121, 440AX122, 440AX123, 440AX124, 440AX125, 440AX126, 440AX127, 440AX128, 440AX129, 440AX130, 440AX131, 440AX132, 440AX133, 440AX134, 440AX135, 440AX136, 440AX137, 440AX138, 440AX139, 440AX140, 440AX141, 440AX142, 440AX143, 440AX144, 440AX145, 440AX146, 440AX147, 440AX148, 440AX149, 440AX150, 440AX151, 440AX152, 440AX153, 440AX154, 440AX158, 440AX159, 440AX160, 440AX161, 440AX162, 440AX163, 440AX164, 440AX165, 440AX166, 440AX167, 440AX168, 440AX169, 440AX170, 440AX171, 440AX172, 440AX173, 440AX174, 440AX175, 440AX176, 440AX177, 440AX178, 440AX179, 440AX180, 440AX181, 440AX182, 440AX183, 440AX184, 440AX185, 440AX186, 440AX187, 440AX188, 440AX189, 440AX190, 440AX191, 440AX192, 440AX193, 440AX194, 440AX195, 440AX196, 440AX197, 440AX198, 440AX199, 440AX200, 440AX201, 440AX202, 440AX203, 440AX204, 440AX205, 440AX206, 440AX207, 440AX210, 440AX211, 440AX212, Tool (#3), 520X1, 520X3, 520X4, 520X6, 520X7, 520X8, 520X11, 520X12, 520X13, 520X16, 520X17, 520X18, 520X19, 520X21, 520X22, 520X23, 520X24, 520X26, 520X27, 520X28, 520X29, 520X31, 520X32, 520X33, 520X34, 520X36, 520X37, 520X38, 520X39, 520X41, 520X42, 520X43, 520X44, 520X46, 520X47, 520X48, 520X49, 520X51, 520X52, 520X53, 520X54, 520X56, 520X57, 520X58, 520X59, 520X61, 520X62, 520X63, 520X64, 520X66, 520X67, 520X68, 520X69, 520X71, 520X72, 520X73, 520X74, 520X76, 520X77, 520X78, 520X79, 520X81, 520X82, 520X83, 520X84, 520X86, 520X87, 520X88, 520X89, 520X91, 520X92, 520X93, 520X94, 520X96, 520X97, 520X98, 520X99, 520X101, 520X102, 520X103, 520X104, 520X106, 520X107, 520X108, 520X109, 520X111, 520X112, 520X113, 520X117, 520X118, 520X119, 520X123, 520X124, 520X128, 520X129, 520X130, 520X134, 520X135, 520X137, 520X140, 520X143, 520X144, 520X158, 520X159, 520X160, 520X161, 520X162, 520X165, 520X166, 520X167, 520X168, 520X169, 520X174, 520X176, 520X177, 520X178, 520X179, 520X180, 520X181, 520X182, 520X183, 520X184, 520X185, 520X186, 520X230, 520X231, 520X232, 520X233, 520X234, 520X235, 520X236, 520X237, 520X238, 520X239, 520X240, 520X241, 520X242, 520X243, 520X244, 520X245, 520X246, 520X252, 520X253, 520X254, 520X255, 520X256, 520X257, 520X258, 520X259, 520X260, 520X261, 520X262, 520X263, 520X264, 520X265, 520X266, 520X267, 520X281, 520X282, 520X283, 520X284, 520X285, 520X287, 520X288, 520X289, 520X290, 520X291, 520X293, 520X294, 520X295, 520X296, 520X297, 520X298, 520X305, 520X306, 520X307, 520X308, 520X309, 520X311, 520X312, 520X313, 520X314, 520X315, 520X317, 520X318, 520X319, 520X320, 520X321, 520X322, 520X323, 520X324, 520X325, 520X326, 520X327, 520X329, 520X330, 520X332, 520X333, 520X345, 520X351, 520X353, 520X375, 520X376, 520X377, 520X380, 520X381, 520X387, 520X388, 520X389, 520X390, 520X391, 520X392, 520X393, 520X394, 520X395, 520X396, 520X397, 520X399, 520X400, 520X403, 520X404, 520X405, 520X406, 520X407, 520X408, 520X409, 520X410, 520X411, 520X412, 520X429, 520X432, TOOL (#2), 750X1, 750X2, 750X23, 750X24, 750X27, 750X34, 750X45, 750X46, 750X49, 750X57, 750X60, 750X90, 750X103, 750X109, 750X111, 750X115, 750X116, 750X118, 750X124, 750X131, 750X132, 750X140, 750X148, 750X155, 750X156, 750X164, 750X175, 750X185, 750X186, 750X197, 750X210, 750X218, 750X228, 750X229, 750X240, 750X251, 750X261, 750X262, 750X273, 750X284, 750X294, 750X295, 750X306, 750X317, 750X327, 750X328, 750X335, 750X336, 750X347, 750X358, 750X368, 750X369, 750X380, 750X391, 750X401, 750X402, 750X413, 750X424, 750X434, 750X435, 750X446, 750X454, 750X465, 750X475, 750X476, 750X487, 750X498, 750X508, 750X509, 750X520, 750X531, 750X541, 750X542, 750X553, 750X564, 750X572, 750X582, 750X583, 750X594, 750X604, 750X611, 750X612, 750X620, 750X628, 750X635, 750X636, 750X644, 750X652, 750X659, 750X660, 750X668, 750X676, 750X697, 750X702, 750X705, 750X713, 750X717, 750X741, 750X742, 750X745, 750X763, 750X764, 750X775, 750X778, 750X785, 750X789, 750X971, 750X986, 750X988, 750X996, 750X1002, 750X1005, 750X1008, 750X1019, 750X1030, 750X1041, 750X1049, 750X1052, 750X1071, 750X1074, 750X1096, 750X1115, 750X1129, 750X1137, 750X1139, 750X1164, 750X1189, 750X1192, 750X1203, 750X1225, 750X1247, 750X1288, 750X1296, 750X1298, 750X1306, 750X1312, 750X1314, 750X1330, 750X1357, 750X1384"
     ]
    }
   ],
   "source": [
    "xgb_new_train = xgb.DMatrix(train_xgb,train_label)\n",
    "xgb_new_test = xgb.DMatrix(test_data[train_xgb.columns])\n",
    "xgb_new_ans = xgb.train(params,xgb_new_train,80).predict(xgb_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = xgb.cv(params,  \n",
    "                   dtrain=xgb.DMatrix(train_xgb,train_label),  \n",
    "                   nfold=5,  \n",
    "                   num_boost_round=200,  \n",
    "                   early_stopping_rounds=50,  \n",
    "                   verbose_eval=30,  \n",
    "                   show_stdv=False  \n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-8e0e7d0d5d52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train_pearson\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcv_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcv_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_result = cv(lgb.LGBMRegressor(),X_train_pearson,train_label,cv=10,n_jobs=4,scoring='mean_squared_error')\n",
    "cv_result = -cv_result\n",
    "print(cv_result.mean())\n",
    "print(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0251844255099\n",
      "[ 0.024452    0.02629732  0.02658323  0.01758197  0.0194486   0.01930756\n",
      "  0.01996994  0.0124339   0.03278507  0.05298469]\n"
     ]
    }
   ],
   "source": [
    "cv_result = cv(xgb.XGBRegressor(),X_train_kendall,train_label,cv=10,n_jobs=4,scoring='mean_squared_error')\n",
    "cv_result = -cv_result\n",
    "print(cv_result.mean())\n",
    "print(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "gbdt_model = GBR().fit(X_train_pearson[feature_3_name_std],train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_feature(feature_name,model,num):\n",
    "    sub = DF()\n",
    "    sub['name'] = feature_name\n",
    "    sub['score'] = model.feature_importances_\n",
    "    return list(sub.sort_values(by=['score'],ascending=False).head(num)['name'])\n",
    "\n",
    "def get_min_max(train,test,feature_name,method):\n",
    "    if method == 'Diff':\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        X_train_minmax = DF(min_max_scaler.fit_transform(train[feature_name]),columns=train[feature_name].columns)\n",
    "        del min_max_scaler\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        X_test_minmax = DF(min_max_scaler.fit_transform(test[feature_name]),columns=test[feature_name].columns)\n",
    "        del min_max_scaler\n",
    "        \n",
    "    elif method == 'All':\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        merge = pd.concat([train,test],axis=0)\n",
    "        X_train_minmax = DF(min_max_scaler.fit_transform(merge[feature_name]),columns=train[feature_name].columns)[:(len(train))]\n",
    "        X_test_minmax = DF(min_max_scaler.fit_transform(merge[feature_name]),columns=train[feature_name].columns)[(len(train)):]\n",
    "        del min_max_scaler\n",
    "        \n",
    "    return X_train_minmax, X_test_minmax\n",
    "        \n",
    "\n",
    "def calc_feature_choose(train,test,feature_name):\n",
    "    X_train_minmax,X_test_minmax = get_min_max(train,test,feature_name,'Diff') \n",
    "    model1 = xgb.XGBRegressor(n_estimators=190).fit(train[feature_name],train_label)\n",
    "    model2 = lgb.LGBMRegressor(n_estimators=130).fit(train[feature_name],train_label)\n",
    "    model3 = SVR(kernel='rbf').fit(X_train_minmax[feature_name],train_label)\n",
    "    model4 = Ridge().fit(train[feature_name],train_label)\n",
    "    model5 = GBR().fit(train[feature_name],train_label)\n",
    "    ans1 = model1.predict(test[feature_name])\n",
    "    ans2 = model2.predict(test[feature_name])\n",
    "    ans3 = model3.predict(X_test_minmax[feature_name])\n",
    "    ans4 = model4.predict(test[feature_name])\n",
    "    ans5 = model5.predict(test[feature_name])\n",
    "    return (ans1+ans2+ans3+ans4+ans5)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 3404)\n",
      "(799, 2245)\n",
      "50\n",
      "GBDT Finish\n",
      "XGB Finish\n",
      "LGB Finish\n",
      "100\n",
      "GBDT Finish\n",
      "XGB Finish\n",
      "LGB Finish\n",
      "150\n",
      "GBDT Finish\n",
      "XGB Finish\n",
      "LGB Finish\n",
      "200\n",
      "GBDT Finish\n",
      "XGB Finish\n",
      "LGB Finish\n",
      "250\n",
      "GBDT Finish\n",
      "XGB Finish\n",
      "LGB Finish\n",
      "300\n",
      "GBDT Finish\n",
      "XGB Finish\n",
      "LGB Finish\n",
      "350\n",
      "GBDT Finish\n",
      "XGB Finish\n",
      "LGB Finish\n",
      "400\n",
      "GBDT Finish\n",
      "XGB Finish\n",
      "LGB Finish\n",
      "450\n",
      "GBDT Finish\n",
      "XGB Finish\n",
      "LGB Finish\n"
     ]
    }
   ],
   "source": [
    "choose_num = [50,100,150,200,250,300,350,400,450]\n",
    "get_ans = []\n",
    "print(X_train_pearson.shape)\n",
    "now_train = X_train_pearson.T.drop_duplicates().T\n",
    "now_test = X_test_pearson[now_train.columns]\n",
    "feature_name = now_train.columns\n",
    "print(now_train.shape)\n",
    "gbdt_model = GBR().fit(now_train[feature_name],train_label)\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=130,max_depth=7).fit(now_train[feature_name],train_label)\n",
    "xgb_model = xgb.XGBRegressor().fit(now_train[feature_name],train_label)\n",
    "\n",
    "for i in choose_num:\n",
    "    print(i)\n",
    "    get_ans.append(calc_feature_choose(now_train,now_test,get_num_feature(feature_name,gbdt_model,i)))\n",
    "    print('GBDT Finish')\n",
    "    get_ans.append(calc_feature_choose(now_train,now_test,get_num_feature(feature_name,xgb_model,i)))\n",
    "    print('XGB Finish')\n",
    "    get_ans.append(calc_feature_choose(now_train,now_test,get_num_feature(feature_name,lgb_model,i)))\n",
    "    print('LGB Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfc = 0 \n",
    "for i in get_ans:\n",
    "    kfc += i\n",
    "\n",
    "kfc/=len(get_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ans(ans,name):\n",
    "    sub = DF()\n",
    "    sub['ID'] = test_ID\n",
    "    sub['Pre'] = list(ans)\n",
    "    sub.to_csv(name,index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
